<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.6" />
<title>Scenario API documentation</title>
<meta name="description" content="Scenario execution engine for agent testing …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="/favicon.ico" type="image/x-icon" />
</head>
<body>
<style>
.navbar.navbar--fixed-top{
background-color: #fff;
box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.1);
display: flex;
height: 3.75rem;
padding: 0.5rem 1rem;
}
.navbar__inner {
display: flex;
flex-wrap: wrap;
justify-content: space-between;
width: 100%;
}
.navbar__items {
align-items: center;
display: flex;
flex: 1;
min-width: 0;
}
.navbar__items--right {
flex: 0 0 auto;
justify-content: flex-end;
}
.navbar__link {
color: #1c1e21;
font-weight: 500;
}
.navbar__link:hover, .navbar__link--active {
color: #2e8555;
text-decoration: none;
}
.navbar__item {
display: inline-block;
padding: 0.25em 0.75em;
}
.navbar a {
text-decoration: none;
transition: color 200ms cubic-bezier(0.08, 0.52, 0.52, 1);
}
.navbar__brand {
align-items: center;
color: #1c1e21;
display: flex;
margin-right: 1rem;
min-width: 0;
}
.iconExternalLink_node_modules-\@docusaurus-theme-classic-lib-theme-Icon-ExternalLink-styles-module {
margin-left: 0.3rem;
}
</style>
<nav aria-label="Main" class="navbar navbar--fixed-top">
<div class="navbar__inner" style="display: flex;
flex-wrap: wrap;
justify-content: space-between;
width: 100%;">
<div class="navbar__items">
<a class="navbar__brand" href="/scenario/"
><b class="navbar__title text--truncate">Scenario</b></a
><a
aria-current="page"
class="navbar__item navbar__link"
href="/scenario/docs/intro"
>Docs</a
>
<a
aria-current="page"
class="navbar__item navbar__link navbar__link--active"
href="/scenario/reference/scenario/index.html"
>Reference</a
>
</div>
<div class="navbar__items navbar__items--right">
<a
href="https://github.com/langwatch/scenario"
target="_blank"
rel="noopener noreferrer"
class="navbar__item navbar__link"
style="display: flex; align-items: center"
>GitHub<svg
width="13.5"
height="13.5"
aria-hidden="true"
viewBox="0 0 24 24"
class="iconExternalLink_node_modules-@docusaurus-theme-classic-lib-theme-Icon-ExternalLink-styles-module"
>
<path
fill="currentColor"
d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"
></path></svg
></a>
</div>
</div>
<div role="presentation" class="navbar-sidebar__backdrop"></div>
</nav>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scenario.scenario_executor</code></h1>
</header>
<section id="section-intro">
<p>Scenario execution engine for agent testing.</p>
<p>This module contains the core ScenarioExecutor class that orchestrates the execution
of scenario tests, managing the interaction between user simulators, agents under test,
and judge agents to determine test success or failure.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Scenario execution engine for agent testing.

This module contains the core ScenarioExecutor class that orchestrates the execution
of scenario tests, managing the interaction between user simulators, agents under test,
and judge agents to determine test success or failure.
&#34;&#34;&#34;

import sys
from typing import (
    Awaitable,
    Callable,
    Dict,
    List,
    Optional,
    Set,
    Tuple,
    Union,
)
import time
import termcolor
import asyncio
import concurrent.futures

from scenario.config import ScenarioConfig
from scenario._utils import (
    await_if_awaitable,
    check_valid_return_type,
    convert_agent_return_types_to_openai_messages,
    print_openai_messages,
    show_spinner,
)
from openai.types.chat import (
    ChatCompletionMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
)

from .types import AgentInput, AgentRole, ScenarioResult, ScriptStep
from ._error_messages import agent_response_not_awaitable
from .cache import context_scenario
from .agent_adapter import AgentAdapter
from .script import proceed
from pksuid import PKSUID
from .scenario_state import ScenarioState


class ScenarioExecutor:
    &#34;&#34;&#34;
    Core orchestrator for scenario-based agent testing.

    The ScenarioExecutor manages the complete lifecycle of a scenario test, including:
    - Orchestrating conversations between user simulators, agents, and judges
    - Managing turn-based execution flow
    - Handling script-based scenario control
    - Collecting and reporting test results
    - Supporting debug mode for interactive testing

    This class serves as both a builder (for configuration) and an executor (for running tests).
    Most users will interact with it through the high-level `scenario.run()` function rather
    than instantiating it directly.

    Attributes:
        name: Human-readable name for the scenario
        description: Detailed description of what the scenario tests
        agents: List of agent adapters participating in the scenario
        script: Optional list of script steps to control scenario flow
        config: Configuration settings for execution behavior

    Example:
        ```
        # Direct instantiation (less common)
        executor = ScenarioExecutor(
           name=&#34;weather query test&#34;,
           description=&#34;User asks about weather, agent should provide helpful response&#34;,
           agents=[
               weather_agent,
               scenario.UserSimulatorAgent(),
               scenario.JudgeAgent(criteria=[&#34;Agent provides helpful weather info&#34;])
           ],
           max_turns=10,
           verbose=True
        )
        result = await executor._run()

        # Preferred high-level API
        result = await scenario.run(
           name=&#34;weather query test&#34;,
           description=&#34;User asks about weather, agent should provide helpful response&#34;,
           agents=[
               weather_agent,
               scenario.UserSimulatorAgent(),
               scenario.JudgeAgent(criteria=[&#34;Agent provides helpful weather info&#34;])
           ]
        )
        ```

    Note:
        - Scenarios run in isolated thread pools to support parallel execution
        - All agent interactions are cached when cache_key is configured
        - Debug mode allows step-by-step execution with user intervention
        - Results include detailed timing information and conversation history
    &#34;&#34;&#34;

    name: str
    description: str
    agents: List[AgentAdapter]
    script: List[ScriptStep]

    config: ScenarioConfig

    _state: ScenarioState
    _total_start_time: float
    _pending_messages: Dict[int, List[ChatCompletionMessageParam]]

    _pending_roles_on_turn: List[AgentRole] = []
    _pending_agents_on_turn: Set[AgentAdapter] = set()
    _agent_times: Dict[int, float] = {}

    def __init__(
        self,
        name: str,
        description: str,
        agents: List[AgentAdapter] = [],
        script: Optional[List[ScriptStep]] = None,
        # Config
        max_turns: Optional[int] = None,
        verbose: Optional[Union[bool, int]] = None,
        cache_key: Optional[str] = None,
        debug: Optional[bool] = None,
    ):
        &#34;&#34;&#34;
        Initialize a scenario executor.

        Args:
            name: Human-readable name for the scenario (used in reports and logs)
            description: Detailed description of what the scenario tests.
                        This guides the user simulator&#39;s behavior and provides context.
            agents: List of agent adapters participating in the scenario.
                   Typically includes: agent under test, user simulator, and judge.
            script: Optional list of script steps to control scenario flow.
                   If not provided, defaults to automatic proceeding.
            max_turns: Maximum number of conversation turns before timeout.
                      Overrides global configuration for this scenario.
            verbose: Whether to show detailed output during execution.
                    Can be True/False or integer level (2 for extra details).
            cache_key: Cache key for deterministic behavior across runs.
                      Overrides global configuration for this scenario.
            debug: Whether to enable debug mode with step-by-step execution.
                  Overrides global configuration for this scenario.
        &#34;&#34;&#34;
        self.name = name
        self.description = description
        self.agents = agents
        self.script = script or [proceed()]

        config = ScenarioConfig(
            max_turns=max_turns,
            verbose=verbose,
            cache_key=cache_key,
            debug=debug,
        )
        self.config = (ScenarioConfig.default_config or ScenarioConfig()).merge(config)

        self.reset()

    @classmethod
    async def run(
        cls,
        name: str,
        description: str,
        agents: List[AgentAdapter] = [],
        max_turns: Optional[int] = None,
        verbose: Optional[Union[bool, int]] = None,
        cache_key: Optional[str] = None,
        debug: Optional[bool] = None,
        script: Optional[List[ScriptStep]] = None,
    ) -&gt; ScenarioResult:
        &#34;&#34;&#34;
        High-level interface for running a scenario test.

        This is the main entry point for executing scenario tests. It creates a
        ScenarioExecutor instance and runs it in an isolated thread pool to support
        parallel execution and prevent blocking.

        Args:
            name: Human-readable name for the scenario
            description: Detailed description of what the scenario tests
            agents: List of agent adapters (agent under test, user simulator, judge)
            max_turns: Maximum conversation turns before timeout (default: 10)
            verbose: Show detailed output during execution
            cache_key: Cache key for deterministic behavior
            debug: Enable debug mode for step-by-step execution
            script: Optional script steps to control scenario flow

        Returns:
            ScenarioResult containing the test outcome, conversation history,
            success/failure status, and detailed reasoning

        Example:
            ```
            import scenario

            # Simple scenario with automatic flow
            result = await scenario.run(
               name=&#34;help request&#34;,
               description=&#34;User asks for help with a technical problem&#34;,
               agents=[
                   my_agent,
                   scenario.UserSimulatorAgent(),
                   scenario.JudgeAgent(criteria=[&#34;Agent provides helpful response&#34;])
               ]
            )

            # Scripted scenario with custom evaluations
            result = await scenario.run(
               name=&#34;custom interaction&#34;,
               description=&#34;Test specific conversation flow&#34;,
               agents=[
                   my_agent,
                   scenario.UserSimulatorAgent(),
                   scenario.JudgeAgent(criteria=[&#34;Agent provides helpful response&#34;])
               ],
               script=[
                   scenario.user(&#34;Hello&#34;),
                   scenario.agent(),
                   custom_eval,
                   scenario.succeed()
               ]
            )

            # Results analysis
            print(f&#34;Test {&#39;PASSED&#39; if result.success else &#39;FAILED&#39;}&#34;)
            print(f&#34;Reasoning: {result.reasoning}&#34;)
            print(f&#34;Conversation had {len(result.messages)} messages&#34;)
            ```

        Note:
            - Runs in isolated thread pool to support parallel execution
            - Blocks until scenario completes or times out
            - All agent calls are automatically cached when cache_key is set
            - Exception handling ensures clean resource cleanup
        &#34;&#34;&#34;
        scenario = cls(
            name=name,
            description=description,
            agents=agents,
            max_turns=max_turns,
            verbose=verbose,
            cache_key=cache_key,
            debug=debug,
            script=script,
        )

        # We&#39;ll use a thread pool to run the execution logic, we
        # require a separate thread because even though asyncio is
        # being used throughout, any user code on the callback can
        # be blocking, preventing them from running scenarios in parallel
        with concurrent.futures.ThreadPoolExecutor() as executor:

            def run_in_thread():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                try:
                    return loop.run_until_complete(scenario._run())
                finally:
                    loop.close()

            # Run the function in the thread pool and await its result
            # This converts the thread&#39;s execution into a Future that the current
            # event loop can await without blocking
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(executor, run_in_thread)
            return result

    def reset(self):
        &#34;&#34;&#34;
        Reset the scenario executor to initial state.

        This method reinitializes all internal state for a fresh scenario run,
        including conversation history, turn counters, and agent timing information.
        Called automatically during initialization and can be used to rerun scenarios.
        &#34;&#34;&#34;
        self._state = ScenarioState(
            description=self.description,
            messages=[],
            thread_id=str(PKSUID(&#34;thread&#34;)),
            current_turn=0,
            config=self.config,
            _executor=self,
        )
        # Pydantic doesn&#39;t actually set the _executor field from the constructor, as it&#39;s private, so we need to do it manually
        self._state._executor = self

        self._pending_messages = {}
        self._total_start_time = time.time()
        self._agent_times = {}

        self._new_turn()
        self._state.current_turn = 0

        context_scenario.set(self)

    def add_message(
        self, message: ChatCompletionMessageParam, from_agent_idx: Optional[int] = None
    ):
        &#34;&#34;&#34;
        Add a message to the conversation and broadcast to other agents.

        This method adds a message to the conversation history and makes it available
        to other agents in their next call. It&#39;s used internally by the executor
        and can be called from script steps to inject custom messages.

        Args:
            message: OpenAI-compatible message to add to the conversation
            from_agent_idx: Index of the agent that generated this message.
                           Used to avoid broadcasting the message back to its creator.

        Example:
            ```
            def inject_system_message(state: ScenarioState) -&gt; None:
                state.add_message({
                    &#34;role&#34;: &#34;system&#34;,
                    &#34;content&#34;: &#34;The user is now in a hurry&#34;
                })

            # Use in script
            result = await scenario.run(
               name=&#34;system message test&#34;,
               agents=[agent, user_sim, judge],
               script=[
                   scenario.user(&#34;Hello&#34;),
                   scenario.agent(),
                   inject_system_message,
                   scenario.user(),  # Will see the system message
                   scenario.succeed()
               ]
            )
            ```
        &#34;&#34;&#34;
        self._state.messages.append(message)

        # Broadcast the message to other agents
        for idx, _ in enumerate(self.agents):
            if idx == from_agent_idx:
                continue
            if idx not in self._pending_messages:
                self._pending_messages[idx] = []
            self._pending_messages[idx].append(message)

    def add_messages(
        self,
        messages: List[ChatCompletionMessageParam],
        from_agent_idx: Optional[int] = None,
    ):
        &#34;&#34;&#34;
        Add multiple messages to the conversation.

        Convenience method for adding multiple messages at once. Each message
        is added individually using add_message().

        Args:
            messages: List of OpenAI-compatible messages to add
            from_agent_idx: Index of the agent that generated these messages

        Example:
            ```
            # Agent returns multiple messages for a complex interaction
            messages = [
                {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Let me search for that...&#34;},
                {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Here&#39;s what I found: ...&#34;}
            ]
            executor.add_messages(messages, from_agent_idx=0)
            ```
        &#34;&#34;&#34;
        for message in messages:
            self.add_message(message, from_agent_idx)

    def _new_turn(self):
        self._pending_agents_on_turn = set(self.agents)
        self._pending_roles_on_turn = [
            AgentRole.USER,
            AgentRole.AGENT,
            AgentRole.JUDGE,
        ]
        self._state.current_turn += 1

    async def step(self) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult]:
        &#34;&#34;&#34;
        Execute a single step in the scenario.

        A step consists of calling the next agent in the current turn&#39;s sequence
        and processing their response. This method is used internally by the
        scenario execution flow.

        Returns:
            Either a list of messages (if the scenario continues) or a
            ScenarioResult (if the scenario should end)

        Raises:
            ValueError: If no result is returned from the internal step method

        Note:
            This is primarily an internal method. Most users should use the
            high-level run() method or script DSL functions instead.
        &#34;&#34;&#34;
        result = await self._step()
        if result is None:
            raise ValueError(&#34;No result from step&#34;)
        return result

    async def _step(
        self,
        go_to_next_turn=True,
        on_turn: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
    ) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult, None]:
        if len(self._pending_roles_on_turn) == 0:
            if not go_to_next_turn:
                return None

            self._new_turn()

            if on_turn:
                await await_if_awaitable(on_turn(self._state))

            if self._state.current_turn &gt;= (self.config.max_turns or 10):
                return self._reached_max_turns()

        current_role = self._pending_roles_on_turn[0]
        idx, next_agent = self._next_agent_for_role(current_role)
        if not next_agent:
            self._pending_roles_on_turn.pop(0)
            return await self._step(go_to_next_turn=go_to_next_turn, on_turn=on_turn)

        self._pending_agents_on_turn.remove(next_agent)
        return await self._call_agent(idx, role=current_role)

    def _next_agent_for_role(
        self, role: AgentRole
    ) -&gt; Tuple[int, Optional[AgentAdapter]]:
        for idx, agent in enumerate(self.agents):
            if (
                role == agent.role
                and agent in self._pending_agents_on_turn
                and agent.role in self._pending_roles_on_turn
            ):
                return idx, agent
        return -1, None

    def _reached_max_turns(self, error_message: Optional[str] = None) -&gt; ScenarioResult:
        # If we reached max turns without conclusion, fail the test
        agent_roles_agents_idx = [
            idx
            for idx, agent in enumerate(self.agents)
            if agent.role == AgentRole.AGENT
        ]
        agent_times = [
            self._agent_times[idx]
            for idx in agent_roles_agents_idx
            if idx in self._agent_times
        ]
        agent_time = sum(agent_times)

        return ScenarioResult(
            success=False,
            messages=self._state.messages,
            reasoning=error_message
            or f&#34;Reached maximum turns ({self.config.max_turns or 10}) without conclusion&#34;,
            total_time=time.time() - self._total_start_time,
            agent_time=agent_time,
        )

    async def _run(self) -&gt; ScenarioResult:
        &#34;&#34;&#34;
        Run a scenario against the agent under test.

        Args:
            context: Optional initial context for the agent

        Returns:
            ScenarioResult containing the test outcome
        &#34;&#34;&#34;

        if self.config.verbose:
            print(&#34;&#34;)  # new line

        self.reset()

        for script_step in self.script:
            callable = script_step(self._state)
            if isinstance(callable, Awaitable):
                result = await callable
            else:
                result = callable

            if isinstance(result, ScenarioResult):
                return result

        return self._reached_max_turns(
            &#34;&#34;&#34;Reached end of script without conclusion, add one of the following to the end of the script:

- `scenario.proceed()` to let the simulation continue to play out
- `scenario.judge()` to force criteria judgement
- `scenario.succeed()` or `scenario.fail()` to end the test with an explicit result
            &#34;&#34;&#34;
        )

    async def _call_agent(
        self, idx: int, role: AgentRole, request_judgment: bool = False
    ) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult]:
        agent = self.agents[idx]

        if role == AgentRole.USER and self.config.debug:
            print(
                f&#34;\n{self._scenario_name()}{termcolor.colored(&#39;[Debug Mode]&#39;, &#39;yellow&#39;)} Press enter to continue or type a message to send&#34;
            )
            input_message = input(
                self._scenario_name() + termcolor.colored(&#34;User: &#34;, &#34;green&#34;)
            )

            # Clear the input prompt lines completely
            for _ in range(3):
                sys.stdout.write(&#34;\033[F&#34;)  # Move up to the input line
                sys.stdout.write(&#34;\033[2K&#34;)  # Clear the entire input line
            sys.stdout.flush()  # Make sure the clearing is visible

            if input_message:
                return [
                    ChatCompletionUserMessageParam(role=&#34;user&#34;, content=input_message)
                ]

        with show_spinner(
            text=(
                &#34;Judging...&#34;
                if role == AgentRole.JUDGE
                else f&#34;{role.value if isinstance(role, AgentRole) else role}:&#34;
            ),
            color=(
                &#34;blue&#34;
                if role == AgentRole.AGENT
                else &#34;green&#34; if role == AgentRole.USER else &#34;yellow&#34;
            ),
            enabled=self.config.verbose,
        ):
            start_time = time.time()

            agent_response = agent.call(
                AgentInput(
                    # TODO: test thread_id
                    thread_id=self._state.thread_id,
                    messages=self._state.messages,
                    new_messages=self._pending_messages.get(idx, []),
                    judgment_request=request_judgment,
                    scenario_state=self._state,
                )
            )
            if not isinstance(agent_response, Awaitable):
                raise Exception(
                    agent_response_not_awaitable(agent.__class__.__name__),
                )

            agent_response = await agent_response

            if idx not in self._agent_times:
                self._agent_times[idx] = 0
            self._agent_times[idx] += time.time() - start_time

            self._pending_messages[idx] = []
            check_valid_return_type(agent_response, agent.__class__.__name__)

            messages = []
            if isinstance(agent_response, ScenarioResult):
                # TODO: should be an event
                return agent_response
            else:
                messages = convert_agent_return_types_to_openai_messages(
                    agent_response,
                    role=&#34;user&#34; if role == AgentRole.USER else &#34;assistant&#34;,
                )

            self.add_messages(messages, from_agent_idx=idx)

            if messages and self.config.verbose:
                print_openai_messages(
                    self._scenario_name(),
                    [m for m in messages if m[&#34;role&#34;] != &#34;system&#34;],
                )

            return messages

    def _scenario_name(self):
        if self.config.verbose == 2:
            return termcolor.colored(f&#34;[Scenario: {self.name}] &#34;, &#34;yellow&#34;)
        else:
            return &#34;&#34;

    # Scripting utils

    async def message(self, message: ChatCompletionMessageParam) -&gt; None:
        if message[&#34;role&#34;] == &#34;user&#34;:
            await self._script_call_agent(AgentRole.USER, message)
        elif message[&#34;role&#34;] == &#34;assistant&#34;:
            await self._script_call_agent(AgentRole.AGENT, message)
        else:
            self.add_message(message)

    async def user(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; None:
        await self._script_call_agent(AgentRole.USER, content)

    async def agent(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; None:
        await self._script_call_agent(AgentRole.AGENT, content)

    async def judge(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; Optional[ScenarioResult]:
        return await self._script_call_agent(
            AgentRole.JUDGE, content, request_judgment=True
        )

    async def proceed(
        self,
        turns: Optional[int] = None,
        on_turn: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
        on_step: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
    ) -&gt; Optional[ScenarioResult]:
        initial_turn: Optional[int] = None
        while True:
            next_message = await self._step(
                on_turn=on_turn,
                go_to_next_turn=(
                    turns is None
                    or initial_turn is None
                    or (self._state.current_turn + 1 &lt; initial_turn + turns)
                ),
            )

            if initial_turn is None:
                initial_turn = self._state.current_turn

            if next_message is None:
                break

            if on_step:
                await await_if_awaitable(on_step(self._state))

            if isinstance(next_message, ScenarioResult):
                return next_message

    async def succeed(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
        return ScenarioResult(
            success=True,
            messages=self._state.messages,
            reasoning=reasoning
            or &#34;Scenario marked as successful with scenario.succeed()&#34;,
        )

    async def fail(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
        return ScenarioResult(
            success=False,
            messages=self._state.messages,
            reasoning=reasoning or &#34;Scenario marked as failed with scenario.fail()&#34;,
        )

    def _consume_until_role(self, role: AgentRole) -&gt; None:
        while len(self._pending_roles_on_turn) &gt; 0:
            next_role = self._pending_roles_on_turn[0]
            if next_role == role:
                break
            self._pending_roles_on_turn.pop(0)

    async def _script_call_agent(
        self,
        role: AgentRole,
        content: Optional[Union[str, ChatCompletionMessageParam]] = None,
        request_judgment: bool = False,
    ) -&gt; Optional[ScenarioResult]:
        self._consume_until_role(role)
        idx, next_agent = self._next_agent_for_role(role)
        if not next_agent:
            self._new_turn()
            self._consume_until_role(role)
            idx, next_agent = self._next_agent_for_role(role)

            if not next_agent:
                role_class = (
                    &#34;a scenario.UserSimulatorAgent()&#34;
                    if role == AgentRole.USER
                    else (
                        &#34;a scenario.JudgeAgent()&#34;
                        if role == AgentRole.JUDGE
                        else &#34;your agent&#34;
                    )
                )
                if content:
                    raise ValueError(
                        f&#34;Cannot generate a message for role `{role.value}` with content `{content}` because no agent with this role was found, please add {role_class} to the scenario `agents` list&#34;
                    )
                raise ValueError(
                    f&#34;Cannot generate a message for role `{role.value}` because no agent with this role was found, please add {role_class} to the scenario `agents` list&#34;
                )

        self._pending_agents_on_turn.remove(next_agent)

        if content:
            if isinstance(content, str):
                message = (
                    ChatCompletionUserMessageParam(role=&#34;user&#34;, content=content)
                    if role == AgentRole.USER
                    else ChatCompletionAssistantMessageParam(
                        role=&#34;assistant&#34;, content=content
                    )
                )
            else:
                message = content

            self.add_message(message)
            if self.config.verbose:
                print_openai_messages(self._scenario_name(), [message])
            return

        result = await self._call_agent(
            idx, role=role, request_judgment=request_judgment
        )
        if isinstance(result, ScenarioResult):
            return result</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="scenario.scenario_executor.ScenarioExecutor"><code class="flex name class">
<span>class <span class="ident">ScenarioExecutor</span></span>
<span>(</span><span>name: str, description: str, agents: List[<a title="scenario.agent_adapter.AgentAdapter" href="agent_adapter.html#scenario.agent_adapter.AgentAdapter">AgentAdapter</a>] = [], script: List[Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | Callable[[ForwardRef('ScenarioState')], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]] | None = None, max_turns: int | None = None, verbose: bool | int | None = None, cache_key: str | None = None, debug: bool | None = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Core orchestrator for scenario-based agent testing.</p>
<p>The ScenarioExecutor manages the complete lifecycle of a scenario test, including:
- Orchestrating conversations between user simulators, agents, and judges
- Managing turn-based execution flow
- Handling script-based scenario control
- Collecting and reporting test results
- Supporting debug mode for interactive testing</p>
<p>This class serves as both a builder (for configuration) and an executor (for running tests).
Most users will interact with it through the high-level <code><a title="scenario.run" href="index.html#scenario.run">ScenarioExecutor.run()</a></code> function rather
than instantiating it directly.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Human-readable name for the scenario</dd>
<dt><strong><code>description</code></strong></dt>
<dd>Detailed description of what the scenario tests</dd>
<dt><strong><code>agents</code></strong></dt>
<dd>List of agent adapters participating in the scenario</dd>
<dt><strong><code>script</code></strong></dt>
<dd>Optional list of script steps to control scenario flow</dd>
<dt><strong><code>config</code></strong></dt>
<dd>Configuration settings for execution behavior</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code># Direct instantiation (less common)
executor = ScenarioExecutor(
   name=&quot;weather query test&quot;,
   description=&quot;User asks about weather, agent should provide helpful response&quot;,
   agents=[
       weather_agent,
       scenario.UserSimulatorAgent(),
       scenario.JudgeAgent(criteria=[&quot;Agent provides helpful weather info&quot;])
   ],
   max_turns=10,
   verbose=True
)
result = await executor._run()

# Preferred high-level API
result = await scenario.run(
   name=&quot;weather query test&quot;,
   description=&quot;User asks about weather, agent should provide helpful response&quot;,
   agents=[
       weather_agent,
       scenario.UserSimulatorAgent(),
       scenario.JudgeAgent(criteria=[&quot;Agent provides helpful weather info&quot;])
   ]
)
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Scenarios run in isolated thread pools to support parallel execution</li>
<li>All agent interactions are cached when cache_key is configured</li>
<li>Debug mode allows step-by-step execution with user intervention</li>
<li>Results include detailed timing information and conversation history</li>
</ul>
<p>Initialize a scenario executor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Human-readable name for the scenario (used in reports and logs)</dd>
<dt><strong><code>description</code></strong></dt>
<dd>Detailed description of what the scenario tests.
This guides the user simulator's behavior and provides context.</dd>
<dt><strong><code>agents</code></strong></dt>
<dd>List of agent adapters participating in the scenario.
Typically includes: agent under test, user simulator, and judge.</dd>
<dt><strong><code>script</code></strong></dt>
<dd>Optional list of script steps to control scenario flow.
If not provided, defaults to automatic proceeding.</dd>
<dt><strong><code>max_turns</code></strong></dt>
<dd>Maximum number of conversation turns before timeout.
Overrides global configuration for this scenario.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Whether to show detailed output during execution.
Can be True/False or integer level (2 for extra details).</dd>
<dt><strong><code>cache_key</code></strong></dt>
<dd>Cache key for deterministic behavior across runs.
Overrides global configuration for this scenario.</dd>
<dt><strong><code>debug</code></strong></dt>
<dd>Whether to enable debug mode with step-by-step execution.
Overrides global configuration for this scenario.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ScenarioExecutor:
    &#34;&#34;&#34;
    Core orchestrator for scenario-based agent testing.

    The ScenarioExecutor manages the complete lifecycle of a scenario test, including:
    - Orchestrating conversations between user simulators, agents, and judges
    - Managing turn-based execution flow
    - Handling script-based scenario control
    - Collecting and reporting test results
    - Supporting debug mode for interactive testing

    This class serves as both a builder (for configuration) and an executor (for running tests).
    Most users will interact with it through the high-level `scenario.run()` function rather
    than instantiating it directly.

    Attributes:
        name: Human-readable name for the scenario
        description: Detailed description of what the scenario tests
        agents: List of agent adapters participating in the scenario
        script: Optional list of script steps to control scenario flow
        config: Configuration settings for execution behavior

    Example:
        ```
        # Direct instantiation (less common)
        executor = ScenarioExecutor(
           name=&#34;weather query test&#34;,
           description=&#34;User asks about weather, agent should provide helpful response&#34;,
           agents=[
               weather_agent,
               scenario.UserSimulatorAgent(),
               scenario.JudgeAgent(criteria=[&#34;Agent provides helpful weather info&#34;])
           ],
           max_turns=10,
           verbose=True
        )
        result = await executor._run()

        # Preferred high-level API
        result = await scenario.run(
           name=&#34;weather query test&#34;,
           description=&#34;User asks about weather, agent should provide helpful response&#34;,
           agents=[
               weather_agent,
               scenario.UserSimulatorAgent(),
               scenario.JudgeAgent(criteria=[&#34;Agent provides helpful weather info&#34;])
           ]
        )
        ```

    Note:
        - Scenarios run in isolated thread pools to support parallel execution
        - All agent interactions are cached when cache_key is configured
        - Debug mode allows step-by-step execution with user intervention
        - Results include detailed timing information and conversation history
    &#34;&#34;&#34;

    name: str
    description: str
    agents: List[AgentAdapter]
    script: List[ScriptStep]

    config: ScenarioConfig

    _state: ScenarioState
    _total_start_time: float
    _pending_messages: Dict[int, List[ChatCompletionMessageParam]]

    _pending_roles_on_turn: List[AgentRole] = []
    _pending_agents_on_turn: Set[AgentAdapter] = set()
    _agent_times: Dict[int, float] = {}

    def __init__(
        self,
        name: str,
        description: str,
        agents: List[AgentAdapter] = [],
        script: Optional[List[ScriptStep]] = None,
        # Config
        max_turns: Optional[int] = None,
        verbose: Optional[Union[bool, int]] = None,
        cache_key: Optional[str] = None,
        debug: Optional[bool] = None,
    ):
        &#34;&#34;&#34;
        Initialize a scenario executor.

        Args:
            name: Human-readable name for the scenario (used in reports and logs)
            description: Detailed description of what the scenario tests.
                        This guides the user simulator&#39;s behavior and provides context.
            agents: List of agent adapters participating in the scenario.
                   Typically includes: agent under test, user simulator, and judge.
            script: Optional list of script steps to control scenario flow.
                   If not provided, defaults to automatic proceeding.
            max_turns: Maximum number of conversation turns before timeout.
                      Overrides global configuration for this scenario.
            verbose: Whether to show detailed output during execution.
                    Can be True/False or integer level (2 for extra details).
            cache_key: Cache key for deterministic behavior across runs.
                      Overrides global configuration for this scenario.
            debug: Whether to enable debug mode with step-by-step execution.
                  Overrides global configuration for this scenario.
        &#34;&#34;&#34;
        self.name = name
        self.description = description
        self.agents = agents
        self.script = script or [proceed()]

        config = ScenarioConfig(
            max_turns=max_turns,
            verbose=verbose,
            cache_key=cache_key,
            debug=debug,
        )
        self.config = (ScenarioConfig.default_config or ScenarioConfig()).merge(config)

        self.reset()

    @classmethod
    async def run(
        cls,
        name: str,
        description: str,
        agents: List[AgentAdapter] = [],
        max_turns: Optional[int] = None,
        verbose: Optional[Union[bool, int]] = None,
        cache_key: Optional[str] = None,
        debug: Optional[bool] = None,
        script: Optional[List[ScriptStep]] = None,
    ) -&gt; ScenarioResult:
        &#34;&#34;&#34;
        High-level interface for running a scenario test.

        This is the main entry point for executing scenario tests. It creates a
        ScenarioExecutor instance and runs it in an isolated thread pool to support
        parallel execution and prevent blocking.

        Args:
            name: Human-readable name for the scenario
            description: Detailed description of what the scenario tests
            agents: List of agent adapters (agent under test, user simulator, judge)
            max_turns: Maximum conversation turns before timeout (default: 10)
            verbose: Show detailed output during execution
            cache_key: Cache key for deterministic behavior
            debug: Enable debug mode for step-by-step execution
            script: Optional script steps to control scenario flow

        Returns:
            ScenarioResult containing the test outcome, conversation history,
            success/failure status, and detailed reasoning

        Example:
            ```
            import scenario

            # Simple scenario with automatic flow
            result = await scenario.run(
               name=&#34;help request&#34;,
               description=&#34;User asks for help with a technical problem&#34;,
               agents=[
                   my_agent,
                   scenario.UserSimulatorAgent(),
                   scenario.JudgeAgent(criteria=[&#34;Agent provides helpful response&#34;])
               ]
            )

            # Scripted scenario with custom evaluations
            result = await scenario.run(
               name=&#34;custom interaction&#34;,
               description=&#34;Test specific conversation flow&#34;,
               agents=[
                   my_agent,
                   scenario.UserSimulatorAgent(),
                   scenario.JudgeAgent(criteria=[&#34;Agent provides helpful response&#34;])
               ],
               script=[
                   scenario.user(&#34;Hello&#34;),
                   scenario.agent(),
                   custom_eval,
                   scenario.succeed()
               ]
            )

            # Results analysis
            print(f&#34;Test {&#39;PASSED&#39; if result.success else &#39;FAILED&#39;}&#34;)
            print(f&#34;Reasoning: {result.reasoning}&#34;)
            print(f&#34;Conversation had {len(result.messages)} messages&#34;)
            ```

        Note:
            - Runs in isolated thread pool to support parallel execution
            - Blocks until scenario completes or times out
            - All agent calls are automatically cached when cache_key is set
            - Exception handling ensures clean resource cleanup
        &#34;&#34;&#34;
        scenario = cls(
            name=name,
            description=description,
            agents=agents,
            max_turns=max_turns,
            verbose=verbose,
            cache_key=cache_key,
            debug=debug,
            script=script,
        )

        # We&#39;ll use a thread pool to run the execution logic, we
        # require a separate thread because even though asyncio is
        # being used throughout, any user code on the callback can
        # be blocking, preventing them from running scenarios in parallel
        with concurrent.futures.ThreadPoolExecutor() as executor:

            def run_in_thread():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                try:
                    return loop.run_until_complete(scenario._run())
                finally:
                    loop.close()

            # Run the function in the thread pool and await its result
            # This converts the thread&#39;s execution into a Future that the current
            # event loop can await without blocking
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(executor, run_in_thread)
            return result

    def reset(self):
        &#34;&#34;&#34;
        Reset the scenario executor to initial state.

        This method reinitializes all internal state for a fresh scenario run,
        including conversation history, turn counters, and agent timing information.
        Called automatically during initialization and can be used to rerun scenarios.
        &#34;&#34;&#34;
        self._state = ScenarioState(
            description=self.description,
            messages=[],
            thread_id=str(PKSUID(&#34;thread&#34;)),
            current_turn=0,
            config=self.config,
            _executor=self,
        )
        # Pydantic doesn&#39;t actually set the _executor field from the constructor, as it&#39;s private, so we need to do it manually
        self._state._executor = self

        self._pending_messages = {}
        self._total_start_time = time.time()
        self._agent_times = {}

        self._new_turn()
        self._state.current_turn = 0

        context_scenario.set(self)

    def add_message(
        self, message: ChatCompletionMessageParam, from_agent_idx: Optional[int] = None
    ):
        &#34;&#34;&#34;
        Add a message to the conversation and broadcast to other agents.

        This method adds a message to the conversation history and makes it available
        to other agents in their next call. It&#39;s used internally by the executor
        and can be called from script steps to inject custom messages.

        Args:
            message: OpenAI-compatible message to add to the conversation
            from_agent_idx: Index of the agent that generated this message.
                           Used to avoid broadcasting the message back to its creator.

        Example:
            ```
            def inject_system_message(state: ScenarioState) -&gt; None:
                state.add_message({
                    &#34;role&#34;: &#34;system&#34;,
                    &#34;content&#34;: &#34;The user is now in a hurry&#34;
                })

            # Use in script
            result = await scenario.run(
               name=&#34;system message test&#34;,
               agents=[agent, user_sim, judge],
               script=[
                   scenario.user(&#34;Hello&#34;),
                   scenario.agent(),
                   inject_system_message,
                   scenario.user(),  # Will see the system message
                   scenario.succeed()
               ]
            )
            ```
        &#34;&#34;&#34;
        self._state.messages.append(message)

        # Broadcast the message to other agents
        for idx, _ in enumerate(self.agents):
            if idx == from_agent_idx:
                continue
            if idx not in self._pending_messages:
                self._pending_messages[idx] = []
            self._pending_messages[idx].append(message)

    def add_messages(
        self,
        messages: List[ChatCompletionMessageParam],
        from_agent_idx: Optional[int] = None,
    ):
        &#34;&#34;&#34;
        Add multiple messages to the conversation.

        Convenience method for adding multiple messages at once. Each message
        is added individually using add_message().

        Args:
            messages: List of OpenAI-compatible messages to add
            from_agent_idx: Index of the agent that generated these messages

        Example:
            ```
            # Agent returns multiple messages for a complex interaction
            messages = [
                {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Let me search for that...&#34;},
                {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Here&#39;s what I found: ...&#34;}
            ]
            executor.add_messages(messages, from_agent_idx=0)
            ```
        &#34;&#34;&#34;
        for message in messages:
            self.add_message(message, from_agent_idx)

    def _new_turn(self):
        self._pending_agents_on_turn = set(self.agents)
        self._pending_roles_on_turn = [
            AgentRole.USER,
            AgentRole.AGENT,
            AgentRole.JUDGE,
        ]
        self._state.current_turn += 1

    async def step(self) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult]:
        &#34;&#34;&#34;
        Execute a single step in the scenario.

        A step consists of calling the next agent in the current turn&#39;s sequence
        and processing their response. This method is used internally by the
        scenario execution flow.

        Returns:
            Either a list of messages (if the scenario continues) or a
            ScenarioResult (if the scenario should end)

        Raises:
            ValueError: If no result is returned from the internal step method

        Note:
            This is primarily an internal method. Most users should use the
            high-level run() method or script DSL functions instead.
        &#34;&#34;&#34;
        result = await self._step()
        if result is None:
            raise ValueError(&#34;No result from step&#34;)
        return result

    async def _step(
        self,
        go_to_next_turn=True,
        on_turn: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
    ) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult, None]:
        if len(self._pending_roles_on_turn) == 0:
            if not go_to_next_turn:
                return None

            self._new_turn()

            if on_turn:
                await await_if_awaitable(on_turn(self._state))

            if self._state.current_turn &gt;= (self.config.max_turns or 10):
                return self._reached_max_turns()

        current_role = self._pending_roles_on_turn[0]
        idx, next_agent = self._next_agent_for_role(current_role)
        if not next_agent:
            self._pending_roles_on_turn.pop(0)
            return await self._step(go_to_next_turn=go_to_next_turn, on_turn=on_turn)

        self._pending_agents_on_turn.remove(next_agent)
        return await self._call_agent(idx, role=current_role)

    def _next_agent_for_role(
        self, role: AgentRole
    ) -&gt; Tuple[int, Optional[AgentAdapter]]:
        for idx, agent in enumerate(self.agents):
            if (
                role == agent.role
                and agent in self._pending_agents_on_turn
                and agent.role in self._pending_roles_on_turn
            ):
                return idx, agent
        return -1, None

    def _reached_max_turns(self, error_message: Optional[str] = None) -&gt; ScenarioResult:
        # If we reached max turns without conclusion, fail the test
        agent_roles_agents_idx = [
            idx
            for idx, agent in enumerate(self.agents)
            if agent.role == AgentRole.AGENT
        ]
        agent_times = [
            self._agent_times[idx]
            for idx in agent_roles_agents_idx
            if idx in self._agent_times
        ]
        agent_time = sum(agent_times)

        return ScenarioResult(
            success=False,
            messages=self._state.messages,
            reasoning=error_message
            or f&#34;Reached maximum turns ({self.config.max_turns or 10}) without conclusion&#34;,
            total_time=time.time() - self._total_start_time,
            agent_time=agent_time,
        )

    async def _run(self) -&gt; ScenarioResult:
        &#34;&#34;&#34;
        Run a scenario against the agent under test.

        Args:
            context: Optional initial context for the agent

        Returns:
            ScenarioResult containing the test outcome
        &#34;&#34;&#34;

        if self.config.verbose:
            print(&#34;&#34;)  # new line

        self.reset()

        for script_step in self.script:
            callable = script_step(self._state)
            if isinstance(callable, Awaitable):
                result = await callable
            else:
                result = callable

            if isinstance(result, ScenarioResult):
                return result

        return self._reached_max_turns(
            &#34;&#34;&#34;Reached end of script without conclusion, add one of the following to the end of the script:

- `scenario.proceed()` to let the simulation continue to play out
- `scenario.judge()` to force criteria judgement
- `scenario.succeed()` or `scenario.fail()` to end the test with an explicit result
            &#34;&#34;&#34;
        )

    async def _call_agent(
        self, idx: int, role: AgentRole, request_judgment: bool = False
    ) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult]:
        agent = self.agents[idx]

        if role == AgentRole.USER and self.config.debug:
            print(
                f&#34;\n{self._scenario_name()}{termcolor.colored(&#39;[Debug Mode]&#39;, &#39;yellow&#39;)} Press enter to continue or type a message to send&#34;
            )
            input_message = input(
                self._scenario_name() + termcolor.colored(&#34;User: &#34;, &#34;green&#34;)
            )

            # Clear the input prompt lines completely
            for _ in range(3):
                sys.stdout.write(&#34;\033[F&#34;)  # Move up to the input line
                sys.stdout.write(&#34;\033[2K&#34;)  # Clear the entire input line
            sys.stdout.flush()  # Make sure the clearing is visible

            if input_message:
                return [
                    ChatCompletionUserMessageParam(role=&#34;user&#34;, content=input_message)
                ]

        with show_spinner(
            text=(
                &#34;Judging...&#34;
                if role == AgentRole.JUDGE
                else f&#34;{role.value if isinstance(role, AgentRole) else role}:&#34;
            ),
            color=(
                &#34;blue&#34;
                if role == AgentRole.AGENT
                else &#34;green&#34; if role == AgentRole.USER else &#34;yellow&#34;
            ),
            enabled=self.config.verbose,
        ):
            start_time = time.time()

            agent_response = agent.call(
                AgentInput(
                    # TODO: test thread_id
                    thread_id=self._state.thread_id,
                    messages=self._state.messages,
                    new_messages=self._pending_messages.get(idx, []),
                    judgment_request=request_judgment,
                    scenario_state=self._state,
                )
            )
            if not isinstance(agent_response, Awaitable):
                raise Exception(
                    agent_response_not_awaitable(agent.__class__.__name__),
                )

            agent_response = await agent_response

            if idx not in self._agent_times:
                self._agent_times[idx] = 0
            self._agent_times[idx] += time.time() - start_time

            self._pending_messages[idx] = []
            check_valid_return_type(agent_response, agent.__class__.__name__)

            messages = []
            if isinstance(agent_response, ScenarioResult):
                # TODO: should be an event
                return agent_response
            else:
                messages = convert_agent_return_types_to_openai_messages(
                    agent_response,
                    role=&#34;user&#34; if role == AgentRole.USER else &#34;assistant&#34;,
                )

            self.add_messages(messages, from_agent_idx=idx)

            if messages and self.config.verbose:
                print_openai_messages(
                    self._scenario_name(),
                    [m for m in messages if m[&#34;role&#34;] != &#34;system&#34;],
                )

            return messages

    def _scenario_name(self):
        if self.config.verbose == 2:
            return termcolor.colored(f&#34;[Scenario: {self.name}] &#34;, &#34;yellow&#34;)
        else:
            return &#34;&#34;

    # Scripting utils

    async def message(self, message: ChatCompletionMessageParam) -&gt; None:
        if message[&#34;role&#34;] == &#34;user&#34;:
            await self._script_call_agent(AgentRole.USER, message)
        elif message[&#34;role&#34;] == &#34;assistant&#34;:
            await self._script_call_agent(AgentRole.AGENT, message)
        else:
            self.add_message(message)

    async def user(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; None:
        await self._script_call_agent(AgentRole.USER, content)

    async def agent(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; None:
        await self._script_call_agent(AgentRole.AGENT, content)

    async def judge(
        self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
    ) -&gt; Optional[ScenarioResult]:
        return await self._script_call_agent(
            AgentRole.JUDGE, content, request_judgment=True
        )

    async def proceed(
        self,
        turns: Optional[int] = None,
        on_turn: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
        on_step: Optional[
            Union[
                Callable[[&#34;ScenarioState&#34;], None],
                Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
            ]
        ] = None,
    ) -&gt; Optional[ScenarioResult]:
        initial_turn: Optional[int] = None
        while True:
            next_message = await self._step(
                on_turn=on_turn,
                go_to_next_turn=(
                    turns is None
                    or initial_turn is None
                    or (self._state.current_turn + 1 &lt; initial_turn + turns)
                ),
            )

            if initial_turn is None:
                initial_turn = self._state.current_turn

            if next_message is None:
                break

            if on_step:
                await await_if_awaitable(on_step(self._state))

            if isinstance(next_message, ScenarioResult):
                return next_message

    async def succeed(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
        return ScenarioResult(
            success=True,
            messages=self._state.messages,
            reasoning=reasoning
            or &#34;Scenario marked as successful with scenario.succeed()&#34;,
        )

    async def fail(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
        return ScenarioResult(
            success=False,
            messages=self._state.messages,
            reasoning=reasoning or &#34;Scenario marked as failed with scenario.fail()&#34;,
        )

    def _consume_until_role(self, role: AgentRole) -&gt; None:
        while len(self._pending_roles_on_turn) &gt; 0:
            next_role = self._pending_roles_on_turn[0]
            if next_role == role:
                break
            self._pending_roles_on_turn.pop(0)

    async def _script_call_agent(
        self,
        role: AgentRole,
        content: Optional[Union[str, ChatCompletionMessageParam]] = None,
        request_judgment: bool = False,
    ) -&gt; Optional[ScenarioResult]:
        self._consume_until_role(role)
        idx, next_agent = self._next_agent_for_role(role)
        if not next_agent:
            self._new_turn()
            self._consume_until_role(role)
            idx, next_agent = self._next_agent_for_role(role)

            if not next_agent:
                role_class = (
                    &#34;a scenario.UserSimulatorAgent()&#34;
                    if role == AgentRole.USER
                    else (
                        &#34;a scenario.JudgeAgent()&#34;
                        if role == AgentRole.JUDGE
                        else &#34;your agent&#34;
                    )
                )
                if content:
                    raise ValueError(
                        f&#34;Cannot generate a message for role `{role.value}` with content `{content}` because no agent with this role was found, please add {role_class} to the scenario `agents` list&#34;
                    )
                raise ValueError(
                    f&#34;Cannot generate a message for role `{role.value}` because no agent with this role was found, please add {role_class} to the scenario `agents` list&#34;
                )

        self._pending_agents_on_turn.remove(next_agent)

        if content:
            if isinstance(content, str):
                message = (
                    ChatCompletionUserMessageParam(role=&#34;user&#34;, content=content)
                    if role == AgentRole.USER
                    else ChatCompletionAssistantMessageParam(
                        role=&#34;assistant&#34;, content=content
                    )
                )
            else:
                message = content

            self.add_message(message)
            if self.config.verbose:
                print_openai_messages(self._scenario_name(), [message])
            return

        result = await self._call_agent(
            idx, role=role, request_judgment=request_judgment
        )
        if isinstance(result, ScenarioResult):
            return result</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="scenario.scenario_executor.ScenarioExecutor.agents"><code class="name">var <span class="ident">agents</span> : List[<a title="scenario.agent_adapter.AgentAdapter" href="agent_adapter.html#scenario.agent_adapter.AgentAdapter">AgentAdapter</a>]</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.config"><code class="name">var <span class="ident">config</span> : <a title="scenario.config.ScenarioConfig" href="config.html#scenario.config.ScenarioConfig">ScenarioConfig</a></code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.description"><code class="name">var <span class="ident">description</span> : str</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.script"><code class="name">var <span class="ident">script</span> : List[Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]]</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="scenario.scenario_executor.ScenarioExecutor.run"><code class="name flex">
<span>async def <span class="ident">run</span></span>(<span>name: str, description: str, agents: List[<a title="scenario.agent_adapter.AgentAdapter" href="agent_adapter.html#scenario.agent_adapter.AgentAdapter">AgentAdapter</a>] = [], max_turns: int | None = None, verbose: bool | int | None = None, cache_key: str | None = None, debug: bool | None = None, script: List[Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | Callable[[ForwardRef('ScenarioState')], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]] | None = None) ‑> <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>High-level interface for running a scenario test.</p>
<p>This is the main entry point for executing scenario tests. It creates a
ScenarioExecutor instance and runs it in an isolated thread pool to support
parallel execution and prevent blocking.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Human-readable name for the scenario</dd>
<dt><strong><code>description</code></strong></dt>
<dd>Detailed description of what the scenario tests</dd>
<dt><strong><code>agents</code></strong></dt>
<dd>List of agent adapters (agent under test, user simulator, judge)</dd>
<dt><strong><code>max_turns</code></strong></dt>
<dd>Maximum conversation turns before timeout (default: 10)</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Show detailed output during execution</dd>
<dt><strong><code>cache_key</code></strong></dt>
<dd>Cache key for deterministic behavior</dd>
<dt><strong><code>debug</code></strong></dt>
<dd>Enable debug mode for step-by-step execution</dd>
<dt><strong><code>script</code></strong></dt>
<dd>Optional script steps to control scenario flow</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScenarioResult containing the test outcome, conversation history,
success/failure status, and detailed reasoning</p>
<h2 id="example">Example</h2>
<pre><code>import scenario

# Simple scenario with automatic flow
result = await scenario.run(
   name=&quot;help request&quot;,
   description=&quot;User asks for help with a technical problem&quot;,
   agents=[
       my_agent,
       scenario.UserSimulatorAgent(),
       scenario.JudgeAgent(criteria=[&quot;Agent provides helpful response&quot;])
   ]
)

# Scripted scenario with custom evaluations
result = await scenario.run(
   name=&quot;custom interaction&quot;,
   description=&quot;Test specific conversation flow&quot;,
   agents=[
       my_agent,
       scenario.UserSimulatorAgent(),
       scenario.JudgeAgent(criteria=[&quot;Agent provides helpful response&quot;])
   ],
   script=[
       scenario.user(&quot;Hello&quot;),
       scenario.agent(),
       custom_eval,
       scenario.succeed()
   ]
)

# Results analysis
print(f&quot;Test {'PASSED' if result.success else 'FAILED'}&quot;)
print(f&quot;Reasoning: {result.reasoning}&quot;)
print(f&quot;Conversation had {len(result.messages)} messages&quot;)
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Runs in isolated thread pool to support parallel execution</li>
<li>Blocks until scenario completes or times out</li>
<li>All agent calls are automatically cached when cache_key is set</li>
<li>Exception handling ensures clean resource cleanup</li>
</ul></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="scenario.scenario_executor.ScenarioExecutor.add_message"><code class="name flex">
<span>def <span class="ident">add_message</span></span>(<span>self, message: openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam, from_agent_idx: int | None = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a message to the conversation and broadcast to other agents.</p>
<p>This method adds a message to the conversation history and makes it available
to other agents in their next call. It's used internally by the executor
and can be called from script steps to inject custom messages.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>message</code></strong></dt>
<dd>OpenAI-compatible message to add to the conversation</dd>
<dt><strong><code>from_agent_idx</code></strong></dt>
<dd>Index of the agent that generated this message.
Used to avoid broadcasting the message back to its creator.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code>def inject_system_message(state: ScenarioState) -&gt; None:
    state.add_message({
        &quot;role&quot;: &quot;system&quot;,
        &quot;content&quot;: &quot;The user is now in a hurry&quot;
    })

# Use in script
result = await scenario.run(
   name=&quot;system message test&quot;,
   agents=[agent, user_sim, judge],
   script=[
       scenario.user(&quot;Hello&quot;),
       scenario.agent(),
       inject_system_message,
       scenario.user(),  # Will see the system message
       scenario.succeed()
   ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_message(
    self, message: ChatCompletionMessageParam, from_agent_idx: Optional[int] = None
):
    &#34;&#34;&#34;
    Add a message to the conversation and broadcast to other agents.

    This method adds a message to the conversation history and makes it available
    to other agents in their next call. It&#39;s used internally by the executor
    and can be called from script steps to inject custom messages.

    Args:
        message: OpenAI-compatible message to add to the conversation
        from_agent_idx: Index of the agent that generated this message.
                       Used to avoid broadcasting the message back to its creator.

    Example:
        ```
        def inject_system_message(state: ScenarioState) -&gt; None:
            state.add_message({
                &#34;role&#34;: &#34;system&#34;,
                &#34;content&#34;: &#34;The user is now in a hurry&#34;
            })

        # Use in script
        result = await scenario.run(
           name=&#34;system message test&#34;,
           agents=[agent, user_sim, judge],
           script=[
               scenario.user(&#34;Hello&#34;),
               scenario.agent(),
               inject_system_message,
               scenario.user(),  # Will see the system message
               scenario.succeed()
           ]
        )
        ```
    &#34;&#34;&#34;
    self._state.messages.append(message)

    # Broadcast the message to other agents
    for idx, _ in enumerate(self.agents):
        if idx == from_agent_idx:
            continue
        if idx not in self._pending_messages:
            self._pending_messages[idx] = []
        self._pending_messages[idx].append(message)</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.add_messages"><code class="name flex">
<span>def <span class="ident">add_messages</span></span>(<span>self, messages: List[openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam], from_agent_idx: int | None = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Add multiple messages to the conversation.</p>
<p>Convenience method for adding multiple messages at once. Each message
is added individually using add_message().</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>messages</code></strong></dt>
<dd>List of OpenAI-compatible messages to add</dd>
<dt><strong><code>from_agent_idx</code></strong></dt>
<dd>Index of the agent that generated these messages</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code># Agent returns multiple messages for a complex interaction
messages = [
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Let me search for that...&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Here's what I found: ...&quot;}
]
executor.add_messages(messages, from_agent_idx=0)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_messages(
    self,
    messages: List[ChatCompletionMessageParam],
    from_agent_idx: Optional[int] = None,
):
    &#34;&#34;&#34;
    Add multiple messages to the conversation.

    Convenience method for adding multiple messages at once. Each message
    is added individually using add_message().

    Args:
        messages: List of OpenAI-compatible messages to add
        from_agent_idx: Index of the agent that generated these messages

    Example:
        ```
        # Agent returns multiple messages for a complex interaction
        messages = [
            {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Let me search for that...&#34;},
            {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;Here&#39;s what I found: ...&#34;}
        ]
        executor.add_messages(messages, from_agent_idx=0)
        ```
    &#34;&#34;&#34;
    for message in messages:
        self.add_message(message, from_agent_idx)</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.agent"><code class="name flex">
<span>async def <span class="ident">agent</span></span>(<span>self, content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def agent(
    self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
) -&gt; None:
    await self._script_call_agent(AgentRole.AGENT, content)</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.fail"><code class="name flex">
<span>async def <span class="ident">fail</span></span>(<span>self, reasoning: str | None = None) ‑> <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def fail(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
    return ScenarioResult(
        success=False,
        messages=self._state.messages,
        reasoning=reasoning or &#34;Scenario marked as failed with scenario.fail()&#34;,
    )</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.judge"><code class="name flex">
<span>async def <span class="ident">judge</span></span>(<span>self, content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def judge(
    self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
) -&gt; Optional[ScenarioResult]:
    return await self._script_call_agent(
        AgentRole.JUDGE, content, request_judgment=True
    )</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.message"><code class="name flex">
<span>async def <span class="ident">message</span></span>(<span>self, message: openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def message(self, message: ChatCompletionMessageParam) -&gt; None:
    if message[&#34;role&#34;] == &#34;user&#34;:
        await self._script_call_agent(AgentRole.USER, message)
    elif message[&#34;role&#34;] == &#34;assistant&#34;:
        await self._script_call_agent(AgentRole.AGENT, message)
    else:
        self.add_message(message)</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.proceed"><code class="name flex">
<span>async def <span class="ident">proceed</span></span>(<span>self, turns: int | None = None, on_turn: Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | None = None, on_step: Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | None = None) ‑> <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def proceed(
    self,
    turns: Optional[int] = None,
    on_turn: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
    on_step: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
) -&gt; Optional[ScenarioResult]:
    initial_turn: Optional[int] = None
    while True:
        next_message = await self._step(
            on_turn=on_turn,
            go_to_next_turn=(
                turns is None
                or initial_turn is None
                or (self._state.current_turn + 1 &lt; initial_turn + turns)
            ),
        )

        if initial_turn is None:
            initial_turn = self._state.current_turn

        if next_message is None:
            break

        if on_step:
            await await_if_awaitable(on_step(self._state))

        if isinstance(next_message, ScenarioResult):
            return next_message</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the scenario executor to initial state.</p>
<p>This method reinitializes all internal state for a fresh scenario run,
including conversation history, turn counters, and agent timing information.
Called automatically during initialization and can be used to rerun scenarios.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    &#34;&#34;&#34;
    Reset the scenario executor to initial state.

    This method reinitializes all internal state for a fresh scenario run,
    including conversation history, turn counters, and agent timing information.
    Called automatically during initialization and can be used to rerun scenarios.
    &#34;&#34;&#34;
    self._state = ScenarioState(
        description=self.description,
        messages=[],
        thread_id=str(PKSUID(&#34;thread&#34;)),
        current_turn=0,
        config=self.config,
        _executor=self,
    )
    # Pydantic doesn&#39;t actually set the _executor field from the constructor, as it&#39;s private, so we need to do it manually
    self._state._executor = self

    self._pending_messages = {}
    self._total_start_time = time.time()
    self._agent_times = {}

    self._new_turn()
    self._state.current_turn = 0

    context_scenario.set(self)</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.step"><code class="name flex">
<span>async def <span class="ident">step</span></span>(<span>self) ‑> List[openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam] | <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>Execute a single step in the scenario.</p>
<p>A step consists of calling the next agent in the current turn's sequence
and processing their response. This method is used internally by the
scenario execution flow.</p>
<h2 id="returns">Returns</h2>
<p>Either a list of messages (if the scenario continues) or a
ScenarioResult (if the scenario should end)</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If no result is returned from the internal step method</dd>
</dl>
<h2 id="note">Note</h2>
<p>This is primarily an internal method. Most users should use the
high-level run() method or script DSL functions instead.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def step(self) -&gt; Union[List[ChatCompletionMessageParam], ScenarioResult]:
    &#34;&#34;&#34;
    Execute a single step in the scenario.

    A step consists of calling the next agent in the current turn&#39;s sequence
    and processing their response. This method is used internally by the
    scenario execution flow.

    Returns:
        Either a list of messages (if the scenario continues) or a
        ScenarioResult (if the scenario should end)

    Raises:
        ValueError: If no result is returned from the internal step method

    Note:
        This is primarily an internal method. Most users should use the
        high-level run() method or script DSL functions instead.
    &#34;&#34;&#34;
    result = await self._step()
    if result is None:
        raise ValueError(&#34;No result from step&#34;)
    return result</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.succeed"><code class="name flex">
<span>async def <span class="ident">succeed</span></span>(<span>self, reasoning: str | None = None) ‑> <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def succeed(self, reasoning: Optional[str] = None) -&gt; ScenarioResult:
    return ScenarioResult(
        success=True,
        messages=self._state.messages,
        reasoning=reasoning
        or &#34;Scenario marked as successful with scenario.succeed()&#34;,
    )</code></pre>
</details>
</dd>
<dt id="scenario.scenario_executor.ScenarioExecutor.user"><code class="name flex">
<span>async def <span class="ident">user</span></span>(<span>self, content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def user(
    self, content: Optional[Union[str, ChatCompletionMessageParam]] = None
) -&gt; None:
    await self._script_call_agent(AgentRole.USER, content)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<a href="/" style="color: #000">← Back to Docs</a>
<h1>Scenario API Reference</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="scenario" href="index.html">scenario</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="scenario.scenario_executor.ScenarioExecutor" href="#scenario.scenario_executor.ScenarioExecutor">ScenarioExecutor</a></code></h4>
<ul class="two-column">
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.add_message" href="#scenario.scenario_executor.ScenarioExecutor.add_message">add_message</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.add_messages" href="#scenario.scenario_executor.ScenarioExecutor.add_messages">add_messages</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.agent" href="#scenario.scenario_executor.ScenarioExecutor.agent">agent</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.agents" href="#scenario.scenario_executor.ScenarioExecutor.agents">agents</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.config" href="#scenario.scenario_executor.ScenarioExecutor.config">config</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.description" href="#scenario.scenario_executor.ScenarioExecutor.description">description</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.fail" href="#scenario.scenario_executor.ScenarioExecutor.fail">fail</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.judge" href="#scenario.scenario_executor.ScenarioExecutor.judge">judge</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.message" href="#scenario.scenario_executor.ScenarioExecutor.message">message</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.name" href="#scenario.scenario_executor.ScenarioExecutor.name">name</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.proceed" href="#scenario.scenario_executor.ScenarioExecutor.proceed">proceed</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.reset" href="#scenario.scenario_executor.ScenarioExecutor.reset">reset</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.run" href="#scenario.scenario_executor.ScenarioExecutor.run">run</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.script" href="#scenario.scenario_executor.ScenarioExecutor.script">script</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.step" href="#scenario.scenario_executor.ScenarioExecutor.step">step</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.succeed" href="#scenario.scenario_executor.ScenarioExecutor.succeed">succeed</a></code></li>
<li><code><a title="scenario.scenario_executor.ScenarioExecutor.user" href="#scenario.scenario_executor.ScenarioExecutor.user">user</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
