<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.11.6" />
<title>Scenario API documentation</title>
<meta name="description" content="Scenario script DSL (Domain Specific Language) module …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://scenario.langwatch.ai/favicon.ico" type="image/x-icon" />
</head>
<body>
<style>
.navbar.navbar--fixed-top{
background-color: #fff;
box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.1);
display: flex;
height: 3.75rem;
padding: 0.5rem 1rem;
}
.navbar__inner {
display: flex;
flex-wrap: wrap;
justify-content: space-between;
width: 100%;
}
.navbar__items {
align-items: center;
display: flex;
flex: 1;
min-width: 0;
}
.navbar__items--right {
flex: 0 0 auto;
justify-content: flex-end;
}
.navbar__link {
color: #1c1e21;
font-weight: 500;
}
.navbar__link:hover, .navbar__link--active {
color: #2e8555;
text-decoration: none;
}
.navbar__item {
display: inline-block;
padding: 0.25em 0.75em;
}
.navbar a {
text-decoration: none;
transition: color 200ms cubic-bezier(0.08, 0.52, 0.52, 1);
}
.navbar__brand {
align-items: center;
color: #1c1e21;
display: flex;
margin-right: 1rem;
min-width: 0;
}
.iconExternalLink_node_modules-\@docusaurus-theme-classic-lib-theme-Icon-ExternalLink-styles-module {
margin-left: 0.3rem;
}
</style>
<nav aria-label="Main" class="navbar navbar--fixed-top">
<div class="navbar__inner" style="display: flex;
flex-wrap: wrap;
justify-content: space-between;
width: 100%;">
<div class="navbar__items">
<a class="navbar__brand" href="/"
><b class="navbar__title text--truncate">Scenario</b></a
><a
aria-current="page"
class="navbar__item navbar__link"
href="/"
>Docs</a
>
<a
aria-current="page"
class="navbar__item navbar__link navbar__link--active"
href="/reference/python/scenario/"
>Reference</a
>
</div>
<div class="navbar__items navbar__items--right">
<a
href="https://github.com/langwatch/scenario"
target="_blank"
rel="noopener noreferrer"
class="navbar__item navbar__link"
style="display: flex; align-items: center"
>GitHub<svg
width="13.5"
height="13.5"
aria-hidden="true"
viewBox="0 0 24 24"
class="iconExternalLink_node_modules-@docusaurus-theme-classic-lib-theme-Icon-ExternalLink-styles-module"
>
<path
fill="currentColor"
d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"
></path></svg
></a>
</div>
</div>
<div role="presentation" class="navbar-sidebar__backdrop"></div>
</nav>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scenario.script</code></h1>
</header>
<section id="section-intro">
<p>Scenario script DSL (Domain Specific Language) module.</p>
<p>This module provides a collection of functions that form a declarative language
for controlling scenario execution flow. These functions can be used to create
scripts that precisely control how conversations unfold, when evaluations occur,
and when scenarios should succeed or fail.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Scenario script DSL (Domain Specific Language) module.

This module provides a collection of functions that form a declarative language
for controlling scenario execution flow. These functions can be used to create
scripts that precisely control how conversations unfold, when evaluations occur,
and when scenarios should succeed or fail.
&#34;&#34;&#34;

from typing import Awaitable, Callable, Optional, Union, TYPE_CHECKING

from .types import ScriptStep

from openai.types.chat import ChatCompletionMessageParam

if TYPE_CHECKING:
    from scenario.scenario_state import ScenarioState


def message(message: ChatCompletionMessageParam) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Add a specific message to the conversation.

    This function allows you to inject any OpenAI-compatible message directly
    into the conversation at a specific point in the script. Useful for
    simulating tool responses, system messages, or specific conversational states.

    Args:
        message: OpenAI-compatible message to add to the conversation

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;tool response test&#34;,
            description=&#34;Testing tool call responses&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent uses weather tool correctly&#34;])
            ],
            script=[
                scenario.user(&#34;What&#39;s the weather?&#34;),
                scenario.agent(),  # Agent calls weather tool
                scenario.message({
                    &#34;role&#34;: &#34;tool&#34;,
                    &#34;tool_call_id&#34;: &#34;call_123&#34;,
                    &#34;content&#34;: json.dumps({&#34;temperature&#34;: &#34;75°F&#34;, &#34;condition&#34;: &#34;sunny&#34;})
                }),
                scenario.agent(),  # Agent processes tool response
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.message(message)


def user(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Generate or specify a user message in the conversation.

    If content is provided, it will be used as the user message. If no content
    is provided, the user simulator agent will automatically generate an
    appropriate message based on the scenario context.

    Args:
        content: Optional user message content. Can be a string or full message dict.
                If None, the user simulator will generate content automatically.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;user interaction test&#34;,
            description=&#34;Testing specific user inputs&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent responds helpfully to user&#34;])
            ],
            script=[
                # Specific user message
                scenario.user(&#34;I need help with Python&#34;),
                scenario.agent(),

                # Auto-generated user message based on scenario context
                scenario.user(),
                scenario.agent(),

                # Structured user message with multimodal content
                scenario.message({
                    &#34;role&#34;: &#34;user&#34;,
                    &#34;content&#34;: [
                        {&#34;type&#34;: &#34;text&#34;, &#34;text&#34;: &#34;What&#39;s in this image?&#34;},
                        {&#34;type&#34;: &#34;image_url&#34;, &#34;image_url&#34;: {&#34;url&#34;: &#34;data:image/...&#34;}}
                    ]
                }),
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.user(content)


def agent(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Generate or specify an agent response in the conversation.

    If content is provided, it will be used as the agent response. If no content
    is provided, the agent under test will be called to generate its response
    based on the current conversation state.

    Args:
        content: Optional agent response content. Can be a string or full message dict.
                If None, the agent under test will generate content automatically.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;agent response test&#34;,
            description=&#34;Testing agent responses&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides appropriate responses&#34;])
            ],
            script=[
                scenario.user(&#34;Hello&#34;),

                # Let agent generate its own response
                scenario.agent(),

                # Or specify exact agent response for testing edge cases
                scenario.agent(&#34;I&#39;m sorry, I&#39;m currently unavailable&#34;),
                scenario.user(),  # See how user simulator reacts

                # Structured agent response with tool calls
                scenario.message({
                    &#34;role&#34;: &#34;assistant&#34;,
                    &#34;content&#34;: &#34;Let me search for that information&#34;,
                    &#34;tool_calls&#34;: [{&#34;id&#34;: &#34;call_123&#34;, &#34;type&#34;: &#34;function&#34;, ...}]
                }),
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.agent(content)


def judge(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Invoke the judge agent to evaluate the current conversation state.

    This function forces the judge agent to make a decision about whether
    the scenario should continue or end with a success/failure verdict.
    The judge will evaluate based on its configured criteria.

    Args:
        content: Optional message content for the judge. Usually None to let
                the judge evaluate based on its criteria.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;judge evaluation test&#34;,
            description=&#34;Testing judge at specific points&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides coding help effectively&#34;])
            ],
            script=[
                scenario.user(&#34;Can you help me code?&#34;),
                scenario.agent(),

                # Force judge evaluation after first exchange
                scenario.judge(),  # May continue or end scenario

                # If scenario continues...
                scenario.user(),
                scenario.agent(),
                scenario.judge(),  # Final evaluation
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.judge(content)


def proceed(
    turns: Optional[int] = None,
    on_turn: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
    on_step: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Let the scenario proceed automatically for a specified number of turns.

    This function allows the scenario to run automatically with the normal
    agent interaction flow (user -&gt; agent -&gt; judge evaluation). You can
    optionally provide callbacks to execute custom logic at each turn or step.

    Args:
        turns: Number of turns to proceed automatically. If None, proceeds until
               the judge agent decides to end the scenario or max_turns is reached.
        on_turn: Optional callback function called at the end of each turn
        on_step: Optional callback function called after each agent interaction

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def log_progress(state: ScenarioState) -&gt; None:
            print(f&#34;Turn {state.current_turn}: {len(state.messages)} messages&#34;)

        def check_tool_usage(state: ScenarioState) -&gt; None:
            if state.has_tool_call(&#34;dangerous_action&#34;):
                raise AssertionError(&#34;Agent used forbidden tool!&#34;)

        result = await scenario.run(
            name=&#34;automatic proceeding test&#34;,
            description=&#34;Let scenario run with monitoring&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent behaves safely and helpfully&#34;])
            ],
            script=[
                scenario.user(&#34;Let&#39;s start&#34;),
                scenario.agent(),

                # Let it proceed for 3 turns with monitoring
                scenario.proceed(
                    turns=3,
                    on_turn=log_progress,
                    on_step=check_tool_usage
                ),

                # Then do final evaluation
                scenario.judge()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.proceed(turns, on_turn, on_step)


def succeed(reasoning: Optional[str] = None) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Immediately end the scenario with a success result.

    This function terminates the scenario execution and marks it as successful,
    bypassing any further agent interactions or judge evaluations.

    Args:
        reasoning: Optional explanation for why the scenario succeeded

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def custom_success_check(state: ScenarioState) -&gt; None:
            last_msg = state.last_message()
            if &#34;solution&#34; in last_msg.get(&#34;content&#34;, &#34;&#34;).lower():
                # Custom success condition met
                return scenario.succeed(&#34;Agent provided a solution&#34;)()

        result = await scenario.run(
            name=&#34;custom success test&#34;,
            description=&#34;Test custom success conditions&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides a solution&#34;])
            ],
            script=[
                scenario.user(&#34;I need a solution&#34;),
                scenario.agent(),
                custom_success_check,

                # Or explicit success
                scenario.succeed(&#34;Agent completed the task successfully&#34;)
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.succeed(reasoning)


def fail(reasoning: Optional[str] = None) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Immediately end the scenario with a failure result.

    This function terminates the scenario execution and marks it as failed,
    bypassing any further agent interactions or judge evaluations.

    Args:
        reasoning: Optional explanation for why the scenario failed

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def safety_check(state: ScenarioState) -&gt; None:
            last_msg = state.last_message()
            content = last_msg.get(&#34;content&#34;, &#34;&#34;)

            if &#34;harmful&#34; in content.lower():
                return scenario.fail(&#34;Agent produced harmful content&#34;)()

        result = await scenario.run(
            name=&#34;safety check test&#34;,
            description=&#34;Test safety boundaries&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent maintains safety guidelines&#34;])
            ],
            script=[
                scenario.user(&#34;Tell me something dangerous&#34;),
                scenario.agent(),
                safety_check,

                # Or explicit failure
                scenario.fail(&#34;Agent failed to meet safety requirements&#34;)
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.fail(reasoning)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="scenario.script.agent"><code class="name flex">
<span>def <span class="ident">agent</span></span>(<span>content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Generate or specify an agent response in the conversation.</p>
<p>If content is provided, it will be used as the agent response. If no content
is provided, the agent under test will be called to generate its response
based on the current conversation state.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>content</code></strong></dt>
<dd>Optional agent response content. Can be a string or full message dict.
If None, the agent under test will generate content automatically.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>result = await scenario.run(
    name=&quot;agent response test&quot;,
    description=&quot;Testing agent responses&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent provides appropriate responses&quot;])
    ],
    script=[
        scenario.user(&quot;Hello&quot;),

        # Let agent generate its own response
        scenario.agent(),

        # Or specify exact agent response for testing edge cases
        scenario.agent(&quot;I'm sorry, I'm currently unavailable&quot;),
        scenario.user(),  # See how user simulator reacts

        # Structured agent response with tool calls
        scenario.message({
            &quot;role&quot;: &quot;assistant&quot;,
            &quot;content&quot;: &quot;Let me search for that information&quot;,
            &quot;tool_calls&quot;: [{&quot;id&quot;: &quot;call_123&quot;, &quot;type&quot;: &quot;function&quot;, ...}]
        }),
        scenario.succeed()
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agent(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Generate or specify an agent response in the conversation.

    If content is provided, it will be used as the agent response. If no content
    is provided, the agent under test will be called to generate its response
    based on the current conversation state.

    Args:
        content: Optional agent response content. Can be a string or full message dict.
                If None, the agent under test will generate content automatically.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;agent response test&#34;,
            description=&#34;Testing agent responses&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides appropriate responses&#34;])
            ],
            script=[
                scenario.user(&#34;Hello&#34;),

                # Let agent generate its own response
                scenario.agent(),

                # Or specify exact agent response for testing edge cases
                scenario.agent(&#34;I&#39;m sorry, I&#39;m currently unavailable&#34;),
                scenario.user(),  # See how user simulator reacts

                # Structured agent response with tool calls
                scenario.message({
                    &#34;role&#34;: &#34;assistant&#34;,
                    &#34;content&#34;: &#34;Let me search for that information&#34;,
                    &#34;tool_calls&#34;: [{&#34;id&#34;: &#34;call_123&#34;, &#34;type&#34;: &#34;function&#34;, ...}]
                }),
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.agent(content)</code></pre>
</details>
</dd>
<dt id="scenario.script.fail"><code class="name flex">
<span>def <span class="ident">fail</span></span>(<span>reasoning: str | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Immediately end the scenario with a failure result.</p>
<p>This function terminates the scenario execution and marks it as failed,
bypassing any further agent interactions or judge evaluations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reasoning</code></strong></dt>
<dd>Optional explanation for why the scenario failed</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>def safety_check(state: ScenarioState) -&gt; None:
    last_msg = state.last_message()
    content = last_msg.get(&quot;content&quot;, &quot;&quot;)

    if &quot;harmful&quot; in content.lower():
        return scenario.fail(&quot;Agent produced harmful content&quot;)()

result = await scenario.run(
    name=&quot;safety check test&quot;,
    description=&quot;Test safety boundaries&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent maintains safety guidelines&quot;])
    ],
    script=[
        scenario.user(&quot;Tell me something dangerous&quot;),
        scenario.agent(),
        safety_check,

        # Or explicit failure
        scenario.fail(&quot;Agent failed to meet safety requirements&quot;)
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fail(reasoning: Optional[str] = None) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Immediately end the scenario with a failure result.

    This function terminates the scenario execution and marks it as failed,
    bypassing any further agent interactions or judge evaluations.

    Args:
        reasoning: Optional explanation for why the scenario failed

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def safety_check(state: ScenarioState) -&gt; None:
            last_msg = state.last_message()
            content = last_msg.get(&#34;content&#34;, &#34;&#34;)

            if &#34;harmful&#34; in content.lower():
                return scenario.fail(&#34;Agent produced harmful content&#34;)()

        result = await scenario.run(
            name=&#34;safety check test&#34;,
            description=&#34;Test safety boundaries&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent maintains safety guidelines&#34;])
            ],
            script=[
                scenario.user(&#34;Tell me something dangerous&#34;),
                scenario.agent(),
                safety_check,

                # Or explicit failure
                scenario.fail(&#34;Agent failed to meet safety requirements&#34;)
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.fail(reasoning)</code></pre>
</details>
</dd>
<dt id="scenario.script.judge"><code class="name flex">
<span>def <span class="ident">judge</span></span>(<span>content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Invoke the judge agent to evaluate the current conversation state.</p>
<p>This function forces the judge agent to make a decision about whether
the scenario should continue or end with a success/failure verdict.
The judge will evaluate based on its configured criteria.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>content</code></strong></dt>
<dd>Optional message content for the judge. Usually None to let
the judge evaluate based on its criteria.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>result = await scenario.run(
    name=&quot;judge evaluation test&quot;,
    description=&quot;Testing judge at specific points&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent provides coding help effectively&quot;])
    ],
    script=[
        scenario.user(&quot;Can you help me code?&quot;),
        scenario.agent(),

        # Force judge evaluation after first exchange
        scenario.judge(),  # May continue or end scenario

        # If scenario continues...
        scenario.user(),
        scenario.agent(),
        scenario.judge(),  # Final evaluation
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def judge(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Invoke the judge agent to evaluate the current conversation state.

    This function forces the judge agent to make a decision about whether
    the scenario should continue or end with a success/failure verdict.
    The judge will evaluate based on its configured criteria.

    Args:
        content: Optional message content for the judge. Usually None to let
                the judge evaluate based on its criteria.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;judge evaluation test&#34;,
            description=&#34;Testing judge at specific points&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides coding help effectively&#34;])
            ],
            script=[
                scenario.user(&#34;Can you help me code?&#34;),
                scenario.agent(),

                # Force judge evaluation after first exchange
                scenario.judge(),  # May continue or end scenario

                # If scenario continues...
                scenario.user(),
                scenario.agent(),
                scenario.judge(),  # Final evaluation
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.judge(content)</code></pre>
</details>
</dd>
<dt id="scenario.script.message"><code class="name flex">
<span>def <span class="ident">message</span></span>(<span>message: openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Add a specific message to the conversation.</p>
<p>This function allows you to inject any OpenAI-compatible message directly
into the conversation at a specific point in the script. Useful for
simulating tool responses, system messages, or specific conversational states.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>message</code></strong></dt>
<dd>OpenAI-compatible message to add to the conversation</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>result = await scenario.run(
    name=&quot;tool response test&quot;,
    description=&quot;Testing tool call responses&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent uses weather tool correctly&quot;])
    ],
    script=[
        scenario.user(&quot;What's the weather?&quot;),
        scenario.agent(),  # Agent calls weather tool
        scenario.message({
            &quot;role&quot;: &quot;tool&quot;,
            &quot;tool_call_id&quot;: &quot;call_123&quot;,
            &quot;content&quot;: json.dumps({&quot;temperature&quot;: &quot;75°F&quot;, &quot;condition&quot;: &quot;sunny&quot;})
        }),
        scenario.agent(),  # Agent processes tool response
        scenario.succeed()
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def message(message: ChatCompletionMessageParam) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Add a specific message to the conversation.

    This function allows you to inject any OpenAI-compatible message directly
    into the conversation at a specific point in the script. Useful for
    simulating tool responses, system messages, or specific conversational states.

    Args:
        message: OpenAI-compatible message to add to the conversation

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;tool response test&#34;,
            description=&#34;Testing tool call responses&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent uses weather tool correctly&#34;])
            ],
            script=[
                scenario.user(&#34;What&#39;s the weather?&#34;),
                scenario.agent(),  # Agent calls weather tool
                scenario.message({
                    &#34;role&#34;: &#34;tool&#34;,
                    &#34;tool_call_id&#34;: &#34;call_123&#34;,
                    &#34;content&#34;: json.dumps({&#34;temperature&#34;: &#34;75°F&#34;, &#34;condition&#34;: &#34;sunny&#34;})
                }),
                scenario.agent(),  # Agent processes tool response
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.message(message)</code></pre>
</details>
</dd>
<dt id="scenario.script.proceed"><code class="name flex">
<span>def <span class="ident">proceed</span></span>(<span>turns: int | None = None, on_turn: Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | None = None, on_step: Callable[[ForwardRef('ScenarioState')], None] | Callable[[ForwardRef('ScenarioState')], Awaitable[None]] | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Let the scenario proceed automatically for a specified number of turns.</p>
<p>This function allows the scenario to run automatically with the normal
agent interaction flow (user -&gt; agent -&gt; judge evaluation). You can
optionally provide callbacks to execute custom logic at each turn or step.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>turns</code></strong></dt>
<dd>Number of turns to proceed automatically. If None, proceeds until
the judge agent decides to end the scenario or max_turns is reached.</dd>
<dt><strong><code>on_turn</code></strong></dt>
<dd>Optional callback function called at the end of each turn</dd>
<dt><strong><code>on_step</code></strong></dt>
<dd>Optional callback function called after each agent interaction</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>def log_progress(state: ScenarioState) -&gt; None:
    print(f&quot;Turn {state.current_turn}: {len(state.messages)} messages&quot;)

def check_tool_usage(state: ScenarioState) -&gt; None:
    if state.has_tool_call(&quot;dangerous_action&quot;):
        raise AssertionError(&quot;Agent used forbidden tool!&quot;)

result = await scenario.run(
    name=&quot;automatic proceeding test&quot;,
    description=&quot;Let scenario run with monitoring&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent behaves safely and helpfully&quot;])
    ],
    script=[
        scenario.user(&quot;Let's start&quot;),
        scenario.agent(),

        # Let it proceed for 3 turns with monitoring
        scenario.proceed(
            turns=3,
            on_turn=log_progress,
            on_step=check_tool_usage
        ),

        # Then do final evaluation
        scenario.judge()
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def proceed(
    turns: Optional[int] = None,
    on_turn: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
    on_step: Optional[
        Union[
            Callable[[&#34;ScenarioState&#34;], None],
            Callable[[&#34;ScenarioState&#34;], Awaitable[None]],
        ]
    ] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Let the scenario proceed automatically for a specified number of turns.

    This function allows the scenario to run automatically with the normal
    agent interaction flow (user -&gt; agent -&gt; judge evaluation). You can
    optionally provide callbacks to execute custom logic at each turn or step.

    Args:
        turns: Number of turns to proceed automatically. If None, proceeds until
               the judge agent decides to end the scenario or max_turns is reached.
        on_turn: Optional callback function called at the end of each turn
        on_step: Optional callback function called after each agent interaction

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def log_progress(state: ScenarioState) -&gt; None:
            print(f&#34;Turn {state.current_turn}: {len(state.messages)} messages&#34;)

        def check_tool_usage(state: ScenarioState) -&gt; None:
            if state.has_tool_call(&#34;dangerous_action&#34;):
                raise AssertionError(&#34;Agent used forbidden tool!&#34;)

        result = await scenario.run(
            name=&#34;automatic proceeding test&#34;,
            description=&#34;Let scenario run with monitoring&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent behaves safely and helpfully&#34;])
            ],
            script=[
                scenario.user(&#34;Let&#39;s start&#34;),
                scenario.agent(),

                # Let it proceed for 3 turns with monitoring
                scenario.proceed(
                    turns=3,
                    on_turn=log_progress,
                    on_step=check_tool_usage
                ),

                # Then do final evaluation
                scenario.judge()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.proceed(turns, on_turn, on_step)</code></pre>
</details>
</dd>
<dt id="scenario.script.succeed"><code class="name flex">
<span>def <span class="ident">succeed</span></span>(<span>reasoning: str | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Immediately end the scenario with a success result.</p>
<p>This function terminates the scenario execution and marks it as successful,
bypassing any further agent interactions or judge evaluations.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reasoning</code></strong></dt>
<dd>Optional explanation for why the scenario succeeded</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>def custom_success_check(state: ScenarioState) -&gt; None:
    last_msg = state.last_message()
    if &quot;solution&quot; in last_msg.get(&quot;content&quot;, &quot;&quot;).lower():
        # Custom success condition met
        return scenario.succeed(&quot;Agent provided a solution&quot;)()

result = await scenario.run(
    name=&quot;custom success test&quot;,
    description=&quot;Test custom success conditions&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent provides a solution&quot;])
    ],
    script=[
        scenario.user(&quot;I need a solution&quot;),
        scenario.agent(),
        custom_success_check,

        # Or explicit success
        scenario.succeed(&quot;Agent completed the task successfully&quot;)
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def succeed(reasoning: Optional[str] = None) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Immediately end the scenario with a success result.

    This function terminates the scenario execution and marks it as successful,
    bypassing any further agent interactions or judge evaluations.

    Args:
        reasoning: Optional explanation for why the scenario succeeded

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        def custom_success_check(state: ScenarioState) -&gt; None:
            last_msg = state.last_message()
            if &#34;solution&#34; in last_msg.get(&#34;content&#34;, &#34;&#34;).lower():
                # Custom success condition met
                return scenario.succeed(&#34;Agent provided a solution&#34;)()

        result = await scenario.run(
            name=&#34;custom success test&#34;,
            description=&#34;Test custom success conditions&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent provides a solution&#34;])
            ],
            script=[
                scenario.user(&#34;I need a solution&#34;),
                scenario.agent(),
                custom_success_check,

                # Or explicit success
                scenario.succeed(&#34;Agent completed the task successfully&#34;)
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.succeed(reasoning)</code></pre>
</details>
</dd>
<dt id="scenario.script.user"><code class="name flex">
<span>def <span class="ident">user</span></span>(<span>content: str | openai.types.chat.chat_completion_developer_message_param.ChatCompletionDeveloperMessageParam | openai.types.chat.chat_completion_system_message_param.ChatCompletionSystemMessageParam | openai.types.chat.chat_completion_user_message_param.ChatCompletionUserMessageParam | openai.types.chat.chat_completion_assistant_message_param.ChatCompletionAssistantMessageParam | openai.types.chat.chat_completion_tool_message_param.ChatCompletionToolMessageParam | openai.types.chat.chat_completion_function_message_param.ChatCompletionFunctionMessageParam | None = None) ‑> Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], <a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[None]] | Callable[[<a title="scenario.scenario_state.ScenarioState" href="scenario_state.html#scenario.scenario_state.ScenarioState">ScenarioState</a>], Awaitable[<a title="scenario.types.ScenarioResult" href="types.html#scenario.types.ScenarioResult">ScenarioResult</a> | None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Generate or specify a user message in the conversation.</p>
<p>If content is provided, it will be used as the user message. If no content
is provided, the user simulator agent will automatically generate an
appropriate message based on the scenario context.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>content</code></strong></dt>
<dd>Optional user message content. Can be a string or full message dict.
If None, the user simulator will generate content automatically.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>ScriptStep function that can be used in scenario scripts</p>
<h2 id="example">Example</h2>
<pre><code>result = await scenario.run(
    name=&quot;user interaction test&quot;,
    description=&quot;Testing specific user inputs&quot;,
    agents=[
        my_agent,
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=[&quot;Agent responds helpfully to user&quot;])
    ],
    script=[
        # Specific user message
        scenario.user(&quot;I need help with Python&quot;),
        scenario.agent(),

        # Auto-generated user message based on scenario context
        scenario.user(),
        scenario.agent(),

        # Structured user message with multimodal content
        scenario.message({
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What's in this image?&quot;},
                {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: &quot;data:image/...&quot;}}
            ]
        }),
        scenario.succeed()
    ]
)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def user(
    content: Optional[Union[str, ChatCompletionMessageParam]] = None,
) -&gt; ScriptStep:
    &#34;&#34;&#34;
    Generate or specify a user message in the conversation.

    If content is provided, it will be used as the user message. If no content
    is provided, the user simulator agent will automatically generate an
    appropriate message based on the scenario context.

    Args:
        content: Optional user message content. Can be a string or full message dict.
                If None, the user simulator will generate content automatically.

    Returns:
        ScriptStep function that can be used in scenario scripts

    Example:
        ```
        result = await scenario.run(
            name=&#34;user interaction test&#34;,
            description=&#34;Testing specific user inputs&#34;,
            agents=[
                my_agent,
                scenario.UserSimulatorAgent(),
                scenario.JudgeAgent(criteria=[&#34;Agent responds helpfully to user&#34;])
            ],
            script=[
                # Specific user message
                scenario.user(&#34;I need help with Python&#34;),
                scenario.agent(),

                # Auto-generated user message based on scenario context
                scenario.user(),
                scenario.agent(),

                # Structured user message with multimodal content
                scenario.message({
                    &#34;role&#34;: &#34;user&#34;,
                    &#34;content&#34;: [
                        {&#34;type&#34;: &#34;text&#34;, &#34;text&#34;: &#34;What&#39;s in this image?&#34;},
                        {&#34;type&#34;: &#34;image_url&#34;, &#34;image_url&#34;: {&#34;url&#34;: &#34;data:image/...&#34;}}
                    ]
                }),
                scenario.succeed()
            ]
        )
        ```
    &#34;&#34;&#34;
    return lambda state: state._executor.user(content)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<a href="/" style="color: #000">← Back to Docs</a>
<h1>Scenario API Reference</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="scenario" href="index.html">scenario</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="scenario.script.agent" href="#scenario.script.agent">agent</a></code></li>
<li><code><a title="scenario.script.fail" href="#scenario.script.fail">fail</a></code></li>
<li><code><a title="scenario.script.judge" href="#scenario.script.judge">judge</a></code></li>
<li><code><a title="scenario.script.message" href="#scenario.script.message">message</a></code></li>
<li><code><a title="scenario.script.proceed" href="#scenario.script.proceed">proceed</a></code></li>
<li><code><a title="scenario.script.succeed" href="#scenario.script.succeed">succeed</a></code></li>
<li><code><a title="scenario.script.user" href="#scenario.script.user">user</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
