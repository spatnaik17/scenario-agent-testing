import { RefLink } from "../../components/RefLink";

# Scripted Simulations [Precise control over the conversation flow]

While automatic simulations are powerful, sometimes you need precise control over the conversation flow. Scripted simulations let you orchestrate exactly how conversations unfold, when evaluations occur, and what custom logic runs at each step.

## Script Basics

A script is a list of functions that control the conversation flow:

:::code-group

```python [python]
result = await scenario.run(
    name="scripted interaction",
    description="Test specific conversation patterns",
    agents=[
        MyAgent(),
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=["Agent responds helpfully"])
    ],
    script=[
        scenario.user("Hello, I need help"),
        scenario.agent(),
        scenario.judge(),
    ]
)
```

```typescript [typescript]
const result = await scenario.run({
  name: "scripted interaction",
  description: "Test specific conversation patterns",
  agents: [
    myAgent,
    scenario.userSimulatorAgent(),
    scenario.judgeAgent({ criteria: ["Agent responds helpfully"] }),
  ],
  script: [
    scenario.user("Hello, I need help"),
    scenario.agent(),
    scenario.judge(),
  ],
});
```

:::

### Commands List

| Command                                                   | Description                                                             |
| --------------------------------------------------------- | ----------------------------------------------------------------------- |
| [`scenario.user()`](#scenariouser)                        | Generate or add user messages                                           |
| [`scenario.agent()`](#scenarioagent)                      | Generate or add agent messages                                          |
| [`scenario.message()`](#scenariomessage)                  | Add any openai-message format messages to the conversation              |
| [`scenario.judge()`](#scenariojudge)                      | Force judge evaluation at specific points                               |
| [`scenario.proceed()`](#scenarioprocceed)                 | Let the conversation flow automatically for a specified number of turns |
| [`scenario.succeed()`](#scenariosucceed-and-scenariofail) | End the scenario with a specific result                                 |
| [`scenario.fail()`](#scenariosucceed-and-scenariofail)    | End the scenario with a specific result                                 |

## Script Commands

### <RefLink link={{ python: "script.html#scenario.script.user", typescript: "script.html#scenario.script.user" }}>`scenario.user()`</RefLink>

Generate or specify user messages:

:::code-group

```python [python]
script=[
    # Specific user message
    scenario.user("I want to cancel my subscription"),

    # Let user simulator generate message based on scenario
    scenario.user(),

    # Structured message with additional content
    scenario.message({
        "role": "user",
        "content": "What's in this image?",
        "attachments": [{"type": "image", "url": "..."}]
    })
]
```

```typescript [typescript]
const script = [
  // Specific user message
  scenario.user("I want to cancel my subscription"),

  // Let user simulator generate message based on scenario
  scenario.user(),

  // Structured message with additional content
  scenario.message({
    role: "user",
    content: [
        { type: "text", text: "I want to cancel my subscription" },
        { type: "image_url", image_url: { url: "https://example.com/image.png" } },
    ],
  }),
];
```

:::

### <RefLink link={{ python: "script.html#scenario.script.agent", typescript: "script.html#scenario.script.agent" }}>`scenario.agent()`</RefLink>

Generate or specify agent responses:

:::code-group

```python [python]
script=[
    scenario.user("Help me with billing"),

    # Let agent generate response
    scenario.agent(),

    # Or specify exact response for testing
    scenario.agent("I'll help you with billing. Can you provide your account number?"),

    # Structured response with tool calls
    scenario.message({
        "role": "assistant",
        "content": "Let me look up your account",
        "tool_calls": [{"function": {"name": "lookup_account"}}]
    })
]
```

```typescript [typescript]

const script = [
  scenario.user("Help me with billing"),
  scenario.agent(),
  scenario.agent("I'll help you with billing. Can you provide your account number?"),
  scenario.message({
    role: "assistant",
    content: [
      { type: "text", text: "I'll help you with billing. Can you provide your account number?" },
      { type: "tool-call", toolCallId: "lookup_account", toolName: "lookup_account", args: { account_number: "123456" } },
    ],
  }),
];
```

:::

### <RefLink link={{ python: "script.html#scenario.script.message", typescript: "script.html#scenario.script.message" }}>`scenario.message()`</RefLink>

Add any OpenAI-compatible message directly to the conversation:

:::code-group

```python [python]
script=[
    # User message
    scenario.message({"role": "user", "content": "Hello, I need help"}),

    # Assistant message
    scenario.message({"role": "assistant", "content": "I'd be happy to help!"}),

    # Assistant message with tool calls
    scenario.message({
        "role": "assistant",
        "content": "Let me look that up for you",
        "tool_calls": [{
            "id": "call_123",
            "type": "function",
            "function": {
                "name": "search_database",
                "arguments": '{"query": "user question"}'
            }
        }]
    }),

    # Tool response
    scenario.message({
        "role": "tool",
        "tool_call_id": "call_123",
        "content": '{"results": ["result1", "result2"]}'
    }),

    # System message (for context injection)
    scenario.message({
        "role": "system",
        "content": "The user is now in a hurry and needs quick responses"
    }),

    # Multimodal user message
    scenario.message({
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image_url", "image_url": {"url": "data:image/..."}}
        ]
    })
]
```

```typescript [typescript]
import { message } from "@langwatch/scenario/script";

const script = [
  // User message
  message({ role: "user", content: "Hello, I need help" }),

  // Assistant message
  message({ role: "assistant", content: "I'd be happy to help!" }),

  // Assistant message with tool call (CoreMessage format)
  message({
    role: "assistant",
    content: [
      { type: "text", text: "Let me look that up for you" },
      { type: "tool-call", toolCallId: "call_123", toolName: "search_database", args: { query: "user question" } },
    ],
  }),

  // Tool response (CoreMessage format)
  message({
    role: "tool",
    toolCallId: "call_123",
    content: [
      { type: "tool-result", toolCallId: "call_123", result: { results: ["result1", "result2"] } },
    ],
  }),

  // System message
  message({ role: "system", content: "The user is now in a hurry and needs quick responses" }),

  // Multimodal user message
  message({
    role: "user",
    content: [
      { type: "text", text: "What's in this image?" },
      { type: "image_url", image_url: { url: "data:image/..." } },
    ],
  }),
];
```

:::

:::tip
Use <RefLink link={{ python: "script.html#scenario.script.message", typescript: "script.html#scenario.script.message" }} code={{ python: "scenario.message()", typescript: "scenario.message()" }} /> when you need precise control over message structure. For simple text messages, <RefLink link={{ python: "script.html#scenario.script.user", typescript: "script.html#scenario.script.user" }} code={{ python: "scenario.user()", typescript: "scenario.user()" }} /> and <RefLink link={{ python: "script.html#scenario.script.agent", typescript: "script.html#scenario.script.agent" }} code={{ python: "scenario.agent()", typescript: "scenario.agent()" }} /> are more convenient.
:::

### <RefLink link={{ python: "script.html#scenario.script.judge", typescript: "script.html#scenario.script.judge" }}>`scenario.judge()`</RefLink>

Force judge evaluation at specific points:

```python
script=[
    scenario.user("I need help"),
    scenario.agent(),

    # Force judge to evaluate now
    scenario.judge(),

    # If conversation continues...
    scenario.user(),
    scenario.agent(),
    scenario.judge()  # Final evaluation
]
```

### <RefLink link={{ python: "script.html#scenario.script.proceed", typescript: "script.html#scenario.script.proceed" }}>`scenario.proceed()`</RefLink>

Let the conversation flow automatically for a specified number of turns:

```python
script=[
    scenario.user("Start the conversation"),
    scenario.agent(),

    # Let it proceed for 3 turns
    scenario.proceed(turns=3),

    # Then take control again
    scenario.user("Final question"),
    scenario.agent(),
    scenario.succeed()
]
```

### <RefLink link={{ python: "script.html#scenario.script.succeed", typescript: "script.html#scenario.script.succeed" }}>`scenario.succeed()`</RefLink> and <RefLink link={{ python: "script.html#scenario.script.fail", typescript: "script.html#scenario.script.fail" }}>`scenario.fail()`</RefLink>

End the scenario with a specific result:

```python
script=[
    scenario.user("Test message"),
    scenario.agent(),

    # End with success
    scenario.succeed("Agent provided helpful response"),

    # Or end with failure
    scenario.fail("Agent did not meet requirements")
]
```

## Custom Steps and Evaluations

### Custom Assertion Functions

Add custom logic at any point in the conversation:

:::code-group

```python [python]
def check_tool_usage(state: scenario.ScenarioState) -> None:
    """Verify agent called the required tool"""
    assert state.has_tool_call("get_weather"), "Agent should have called weather tool"

    # Get the tool call details
    weather_call = state.last_tool_call("get_weather")
    if weather_call:
        args = json.loads(weather_call["function"]["arguments"])
        assert "location" in args, "Weather tool should include location"

def verify_response_quality(state: scenario.ScenarioState) -> None:
    """Check response meets quality standards"""
    last_message = state.last_message()
    content = last_message.get("content", "")

    assert len(content) > 10, "Response should be substantial"
    assert "sorry" not in content.lower(), "Agent shouldn't apologize unnecessarily"

script=[
    scenario.user("What's the weather in Paris?"),
    scenario.agent(),
    check_tool_usage,        # Custom assertion
    verify_response_quality, # Another custom check
    scenario.succeed()
]
```

```typescript [typescript]

async function check_tool_usage(state: scenario.ScenarioState) {
    // Verify agent called the required tool
    assert state.hasToolCall("get_weather"), "Agent should have called weather tool";

    // Get the tool call details
    const weatherCall = state.lastToolCall("get_weather");
    if (!weatherCall) return;

    const args = JSON.parse(weatherCall.function.arguments);
    if (!args.location) throw new Error("Weather tool should include location");
}

async function verify_response_quality(state: scenario.ScenarioState) {

    const lastMessage = state.lastMessage();
    const content = lastMessage.content;

    if (content.length <= 10) throw new Error("Response should be substantial");
    if (content.toLowerCase().includes("sorry")) throw new Error("Agent shouldn't apologize unnecessarily");

const script = [
  scenario.user("What's the weather in Paris?"),
  scenario.agent(),
  check_tool_usage,
  verify_response_quality,
  scenario.succeed(),
];
```

:::

### Async Custom Steps

Custom steps can be async for external API calls:

:::code-group

```python [python]
async def external_evaluation(state: scenario.ScenarioState) -> None:
    """Run external evaluation service"""
    last_response = state.last_message().get("content", "")

    # Call external service
    eval_result = await external_evaluator.evaluate(
        input=state.last_user_message()["content"],
        output=last_response
    )

    assert eval_result.score > 0.8, f"Quality score too low: {eval_result.score}"

script=[
    scenario.user("Complex query"),
    scenario.agent(),
    external_evaluation,  # Async custom step
    scenario.proceed()
]
```

```typescript [typescript]
async function externalEval(state: scenario.ScenarioState) {
    // Run external evaluation service
    const lastResponse = state.lastMessage().content;

    // Call external service
    const evalResult = await external_evaluator.evaluate(
        input: state.lastUserMessage().content,
        output: lastResponse
    );

    if (evalResult.score <= 0.8) throw new Error(`Quality score too low: ${evalResult.score}`);
}

const script = [
  scenario.user("Complex query"),
  scenario.agent(),
  externalEval,
  scenario.proceed(),
];
```

:::

### Conditional Logic

Use conditional logic to branch based on conversation state:

:::code-group

```python [python]
def conditional_check(state: scenario.ScenarioState) -> Optional[scenario.ScenarioResult]:
    """Branch logic based on agent response"""
    last_message = state.last_message()
    content = last_message.get("content", "").lower()

    if "i don't know" in content:
        return scenario.ScenarioResult(
            success=False,
            messages=state.messages,
            reasoning="Agent should not give up so easily"
        )
    elif "let me help" in content:
        # Continue the conversation
        return None
    else:
        # Force a specific follow-up
        state.add_message({
            "role": "user",
            "content": "Can you be more specific?"
        })
        return None

script=[
    scenario.user("I have a problem"),
    scenario.agent(),
    conditional_check,  # Returns ScenarioResult or None
    scenario.proceed()
]
```

```typescript [typescript]
async function conditionalCheck(state: scenario.ScenarioState) {
    // Branch logic based on agent response
    const lastMessage = state.lastMessage();
    const content = lastMessage.content.toLowerCase();

    if (content.includes("i don't know")) {
        return scenario.ScenarioResult(
            success: false,
            messages: state.messages,
            reasoning: "Agent should not give up so easily"
        );
    } else if (content.includes("let me help")) {
        // Continue the conversation
        return null;
    } else {
        // Force a specific follow-up
        state.addMessage({
            role: "user",
            content: "Can you be more specific?"
        });
        return null;
    }
}

const script = [
  scenario.user("I have a problem"),
  scenario.agent(),
  conditionalCheck,
  scenario.proceed(),
];
```

:::

## Starting from Existing History

Sometimes you want to test scenarios that begin mid-conversation:

### Pre-populate Conversation History

:::code-group

```python [python]
result = await scenario.run(
    name="mid-conversation booking",
    description="User is in the middle of booking a flight and now wants to add hotels",
    agents=[
        TravelAgent(),
        scenario.UserSimulatorAgent(),
        scenario.JudgeAgent(criteria=["Agent handles additional requests smoothly"])
    ],
    script=[
        # Set up previous conversation context
        scenario.message({"role": "user", "content": "I'd like to book a flight"}),
        scenario.message({"role": "assistant", "content": "I'd be happy to help. Where would you like to go?"}),
        scenario.message({"role": "user", "content": "I want to go to Paris"}),
        scenario.message({"role": "assistant", "content": "Great! When would you like to travel?"}),

        # Continue with new interaction
        scenario.user("Actually, can you also help me find hotels?"),
        scenario.agent(),
        scenario.judge()
    ]
)
```

```typescript [typescript]
const script = [
  // Set up previous conversation context
  scenario.message({ role: "user", content: "I'd like to book a flight" }),
  scenario.message({ role: "assistant", content: "I'd be happy to help. Where would you like to go?" }),
  scenario.message({ role: "user", content: "I want to go to Paris" }),
  scenario.message({ role: "assistant", content: "Great! When would you like to travel?" }),

  // Continue with new interaction
  scenario.user("Actually, can you also help me find hotels?"),
  scenario.agent(),
  scenario.judge(),
];

const result = await scenario.run({
  name: "mid-conversation booking",
  description: "User is in the middle of booking a flight and now wants to add hotels",
  agents: [
    travelAgent,
    scenario.userSimulatorAgent(),
    scenario.judgeAgent({ criteria: ["Agent handles additional requests smoothly"] }),
  ],
  script,
});
```

:::

### Load from External Sources

:::code-group

```python [python]
async def load_real_conversation(state: scenario.ScenarioState) -> None:
    """Load conversation from logs or database"""
    conversation_data = await load_conversation_from_db("conversation_123")

    for message in conversation_data:
        state.add_message(message)

script=[
    load_real_conversation,  # Load real conversation
    scenario.user("One more question..."),  # Continue from there
    scenario.agent(),
    scenario.judge()
]
```

```typescript [typescript]
async function loadRealConversation(state: scenario.ScenarioState) {
  // Load conversation from logs or database
  const conversationData = await loadConversationFromDb("conversation_123");
  for (const message of conversationData) {
    state.addMessage(message);
  }
}

const script = [
  loadRealConversation, // Load real conversation
  scenario.user("One more question..."), // Continue from there
  scenario.agent(),
  scenario.judge(),
];
```

:::

### Advanced Flow Control

#### `scenario.proceed()` with Callbacks

:::code-group

```python [python]
def log_turn_progress(state: scenario.ScenarioState) -> None:
    """Log progress after each turn"""
    print(f"Turn {state.current_turn}: {len(state.messages)} messages")

    # Check for concerning patterns
    last_msg = state.last_message().get("content", "")
    if "error" in last_msg.lower():
        print("⚠️  Error detected in conversation")

def safety_check(state: scenario.ScenarioState) -> None:
    """Check each step for safety violations"""
    last_msg = state.last_message()
    if last_msg.get("role") == "assistant":
        content = last_msg.get("content", "").lower()
        if any(word in content for word in ["harmful", "dangerous", "illegal"]):
            raise AssertionError("Safety violation detected")

script=[
    scenario.user("Start conversation"),
    scenario.agent(),

    # Proceed with monitoring
    scenario.proceed(
        turns=5,
        on_turn=log_turn_progress,   # Called after each complete turn
        on_step=safety_check         # Called after each agent interaction
    ),

    scenario.judge()
]
```

```typescript [typescript]
function logTurnProgress(state: scenario.ScenarioState) {
  // Log progress after each turn
  console.log(`Turn ${state.currentTurn}: ${state.messages.length} messages`);
  // Check for concerning patterns
  const lastMsg = state.lastMessage().content;
  if (typeof lastMsg === "string" && lastMsg.toLowerCase().includes("error")) {
    console.warn("⚠️  Error detected in conversation");
  }
}

function safetyCheck(state: scenario.ScenarioState) {
  const lastMsg = state.lastMessage();
  if (lastMsg.role === "assistant") {
    const content = typeof lastMsg.content === "string" ? lastMsg.content.toLowerCase() : "";
    if (["harmful", "dangerous", "illegal"].some(word => content.includes(word))) {
      throw new Error("Safety violation detected");
    }
  }
}

const script = [
  scenario.user("Start conversation"),
  scenario.agent(),
  scenario.proceed(5, logTurnProgress, safetyCheck),
  scenario.judge(),
];
```

:::

### Dynamic Script Modification

:::code-group

```python [python]
def dynamic_script_logic(state: scenario.ScenarioState) -> None:
    """Modify conversation flow based on agent behavior"""
    last_msg = state.last_message().get("content", "")

    if any(msg.get("tool_call_id") for msg in state.messages):
        # Agent made a tool call, let's test error handling
        state.add_message({
            "role": "tool",
            "content": json.dumps({"error": "Service unavailable"}),
            "tool_call_id": "test_call_123"
        })

    # Continue based on agent's response to the error
    if "apologize" in last_msg.lower():
        # Agent apologized, test recovery
        state.add_message({
            "role": "user",
            "content": "Is there another way to help me?"
        })

script=[
    scenario.user("I need current data"),
    scenario.agent(),
    dynamic_script_logic,  # Inject tool error
    scenario.agent(),      # See how agent handles error
    scenario.judge()
]
```

```typescript [typescript]
function dynamicScriptLogic(state: scenario.ScenarioState) {
  const lastMsg = state.lastMessage().content;
  // If any message has a toolCallId, inject a tool error
  if (state.messages.some(m => m.toolCallId)) {
    state.addMessage({
      role: "tool",
      toolCallId: "test_call_123",
      content: [
        { type: "tool-result", toolCallId: "test_call_123", result: { error: "Service unavailable" } },
      ],
    });
  }
  // Continue based on agent's response to the error
  if (typeof lastMsg === "string" && lastMsg.toLowerCase().includes("apologize")) {
    state.addMessage({
      role: "user",
      content: "Is there another way to help me?",
    });
  }
}

const script = [
  scenario.user("I need current data"),
  scenario.agent(),
  dynamicScriptLogic, // Inject tool error
  scenario.agent(),   // See how agent handles error
  scenario.judge(),
];
```

:::

### Combining Scripted and Automatic Flow

:::code-group

```python [python]
script=[
    # Start with specific setup
    scenario.user("I need help with a complex issue"),
    scenario.agent(),

    # Verify initial response
    lambda state: assert "help" in state.last_message().get("content", "").lower(),

    # Let conversation flow naturally for a while
    scenario.proceed(turns=3),

    # Inject a complication
    scenario.user("Actually, I need to change my original request"),
    scenario.agent(),

    # Verify adaptation
    lambda state: assert len(state.last_message().get("content", "")) > 50,

    # Let judge decide final outcome
    scenario.judge()
]
```

```typescript [typescript]
const script = [
  // Start with specific setup
  scenario.user("I need help with a complex issue"),
  scenario.agent(),

  // Verify initial response
  (state) => {
    const content = state.lastMessage().content;
    if (typeof content !== "string" || !content.toLowerCase().includes("help")) {
      throw new Error("Agent did not offer help");
    }
  },

  // Let conversation flow naturally for a while
  scenario.proceed(3),

  // Inject a complication
  scenario.user("Actually, I need to change my original request"),
  scenario.agent(),

  // Verify adaptation
  (state) => {
    const content = state.lastMessage().content;
    if (typeof content !== "string" || content.length <= 50) {
      throw new Error("Agent did not provide a substantial adaptation");
    }
  },

  // Let judge decide final outcome
  scenario.judge(),
];
```

:::

### Best Practices

#### 1. Start Simple

:::code-group

```python [python]
# Start with basic flow
script=[
    scenario.user("Hello"),
    scenario.agent(),
    scenario.succeed()
]

# Then add validation
script=[
    scenario.user("Hello"),
    scenario.agent(),
    lambda state: assert "hello" in state.last_message().get("content", "").lower(),
    scenario.succeed()
]
```

```typescript [typescript]
// Start with basic flow
const script = [
  scenario.user("Hello"),
  scenario.agent(),
  scenario.succeed(),
];

// Then add validation
const scriptWithValidation = [
  scenario.user("Hello"),
  scenario.agent(),
  (state) => {
    const content = state.lastMessage().content;
    if (typeof content !== "string" || !content.toLowerCase().includes("hello")) {
      throw new Error("Agent did not greet properly");
    }
  },
  scenario.succeed(),
];
```

:::

#### 2. Use Descriptive Function Names

:::code-group

```python [python]
def ensure_no_pii_leaked(state: scenario.ScenarioState) -> None:
    content = state.last_message().get("content", "")
    assert "George" not in content, \
        "Agent should not mention the user's real name in responses"

def verify_agent_asks_for_clarification(state: scenario.ScenarioState) -> None:
    content = state.last_message().get("content", "").lower()
    assert any(word in content for word in ["what", "which", "how", "when", "where"]), \
        "Agent should ask clarifying questions"
```

```typescript [typescript]
function ensureNoPiiLeaked(state: scenario.ScenarioState) {
  const content = state.lastMessage().content;
  if (typeof content === "string" && content.includes("George")) {
    throw new Error("Agent should not mention the user's real name in responses");
  }
}

function verifyAgentAsksForClarification(state: scenario.ScenarioState) {
  const content = state.lastMessage().content;
  if (
    typeof content !== "string" ||
    !["what", "which", "how", "when", "where"].some(word => content.toLowerCase().includes(word))
  ) {
    throw new Error("Agent should ask clarifying questions");
  }
}
```

:::

#### 3. Balance Control and Realism

:::code-group

```python [python]
# Over-scripted - too rigid
script=[
    scenario.user("Exact message 1"),
    scenario.agent("Exact response 1"),
    scenario.user("Exact message 2"),
    scenario.agent(),
    ensure_exact_response_2,
    scenario.succeed()
]

# Better - mix of control and automation
script=[
    scenario.user("I need help with billing"),
    scenario.agent(),  # Let agent respond naturally
    lambda state: assert "account" in state.last_message().get("content", "").lower(),
    scenario.proceed(turns=2),  # Allow natural conversation
    scenario.judge()
]
```

```typescript [typescript]
// Over-scripted - too rigid
const rigidScript = [
  scenario.user("Exact message 1"),
  scenario.agent("Exact response 1"),
  scenario.user("Exact message 2"),
  scenario.agent(),
  ensureExactResponse2,
  scenario.succeed(),
];

// Better - mix of control and automation
const betterScript = [
  scenario.user("I need help with billing"),
  scenario.agent(), // Let agent respond naturally
  (state) => {
    const content = state.lastMessage().content;
    if (typeof content !== "string" || !content.toLowerCase().includes("account")) {
      throw new Error("Agent did not mention account");
    }
  },
  scenario.proceed(2), // Allow natural conversation
  scenario.judge(),
];
```

:::

### Integration with External Tools

#### LLM Evaluators

:::code-group

```python [python]
import litellm

async def llm_evaluator(state: scenario.ScenarioState) -> None:
    """Use LLM to evaluate response quality"""
    conversation = "\n".join([
        f"{msg['role']}: {msg.get('content', '')}"
        for msg in state.messages[-4:]  # Last 4 messages
    ])

    evaluation_prompt = f"""
    Evaluate this customer service conversation:
    {conversation}

    Is the agent response professional and helpful? Respond with just "yes" or "no".
    """

    response = await litellm.completion(
        model="openai/gpt-4o-mini",
        messages=[{"role": "user", "content": evaluation_prompt}]
    )

    result = response.choices[0].message.content.strip().lower()
    assert result == "yes", f"LLM evaluation failed: {result}"

script=[
    scenario.user("I'm frustrated with my service"),
    scenario.agent(),
    llm_evaluator,  # External LLM evaluation
    scenario.proceed()
]
```

```typescript [typescript]
async function llmEvaluator(state: scenario.ScenarioState) {
  // Use LLM to evaluate response quality
  const conversation = state.messages.slice(-4).map(
    msg => `${msg.role}: ${typeof msg.content === "string" ? msg.content : JSON.stringify(msg.content)}`
  ).join("\n");

  const evaluationPrompt = `
    Evaluate this customer service conversation:
    ${conversation}

    Is the agent response professional and helpful? Respond with just "yes" or "no".
  `;

  const response = await openai.completion({
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: evaluationPrompt }],
  });

  const result = response.choices[0].message.content.trim().toLowerCase();
  if (result !== "yes") throw new Error(`LLM evaluation failed: ${result}`);
}

const script = [
  scenario.user("I'm frustrated with my service"),
  scenario.agent(),
  llmEvaluator, // External LLM evaluation
  scenario.proceed(),
];
```

:::

#### Database Validation

:::code-group

```python [python]
async def verify_database_update(state: scenario.ScenarioState) -> None:
    """Verify agent actually updated the database"""
    # Extract customer ID from conversation
    messages_text = str(state.messages)

    # This would be actual database check
    customer_updated = await check_customer_record_updated(
        customer_id="extracted_from_conversation"
    )

    assert customer_updated, "Agent should have updated customer record"

script=[
    scenario.user("Please update my contact information"),
    scenario.agent(),
    verify_database_update,  # Verify actual system changes
    scenario.succeed("Contact information updated successfully")
]
```

```typescript [typescript]
async function verifyDatabaseUpdate(state: scenario.ScenarioState) {
  // Extract customer ID from conversation
  const messagesText = JSON.stringify(state.messages);
  // This would be actual database check
  const customerUpdated = await checkCustomerRecordUpdated("extracted_from_conversation");
  if (!customerUpdated) throw new Error("Agent should have updated customer record");
}

const script = [
  scenario.user("Please update my contact information"),
  scenario.agent(),
  verifyDatabaseUpdate, // Verify actual system changes
  scenario.succeed("Contact information updated successfully"),
];
```

:::

## Next Steps

Now that you understand scripted simulations, explore other advanced features:

- [Cache](/basics/cache) - Make your tests deterministic and faster
- [Debug Mode](/basics/debug-mode) - Debug scenarios interactively
- [Agent Integration](/agent-integration) - Connect different types of agents
